{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# PDFs\n",
    "import pdfplumber\n",
    "\n",
    "# LLMs\n",
    "import textwrap\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.graphs.graph_document import (\n",
    "    GraphDocument,\n",
    "    Node as BaseNode,\n",
    "    Relationship as BaseRelationship,\n",
    ")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from openai import OpenAI\n",
    "import tiktoken \n",
    "\n",
    "# Neo4j\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import AuthError\n",
    "\n",
    "# Typing & Validation\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Any, Dict, List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing PDFs\n",
    "pdf_directory = \"./reports_ie/\"\n",
    "\n",
    "# List all PDF files in the directory\n",
    "pdf_files = [f for f in os.listdir(pdf_directory) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "for file in pdf_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify file name that you want to process\n",
    "pdf_name = \"IE-10404 - 230222 Broken Rail Emly.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regex patterns to identify the start of the summary and contents sections\n",
    "SUMMARY_PATTERN = re.compile(r\"^summary\", re.IGNORECASE)\n",
    "CONTENTS_PATTERN = re.compile(r\"^contents\", re.IGNORECASE)\n",
    "\n",
    "# Define function to extract the summary section from Ireland reports\n",
    "def extract_summary_section(pdf_path: str, header_lines: int = 1) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from 'Summary' to 'Contents' in an Irish rail report PDF.\n",
    "    If no summary section is found, returns the text from all pages.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"File not found: {pdf_path}\")\n",
    "\n",
    "    summary_text = \"\"\n",
    "    full_text = \"\"\n",
    "    capturing = False  \n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text_lines = page_text.split(\"\\n\")\n",
    "                text_without_header = text_lines[header_lines:]\n",
    "                page_content = f\"[Page {page.page_number}]\\n\" + \"\\n\".join(text_without_header) + \"\\n\\n\"\n",
    "\n",
    "                # Always append to full_text\n",
    "                full_text += page_content\n",
    "\n",
    "                if text_without_header:\n",
    "                    first_line = text_without_header[0].strip().lower()\n",
    "\n",
    "                    if SUMMARY_PATTERN.match(first_line):\n",
    "                        capturing = True\n",
    "                    \n",
    "                    if CONTENTS_PATTERN.match(first_line) and capturing:\n",
    "                        # Stop capturing when \"Contents\" is found after summary started.\n",
    "                        break\n",
    "                    \n",
    "                    if capturing:\n",
    "                        summary_text += page_content\n",
    "\n",
    "    if not summary_text:\n",
    "        print(f\"Warning: No summary section found in {pdf_path}. Returning full text.\")\n",
    "        return full_text\n",
    "\n",
    "    return summary_text\n",
    "\n",
    "# Example usage:\n",
    "pdf_text = extract_summary_section(f\"./reports_ie/{pdf_name}\", header_lines=1)\n",
    "print(pdf_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Chunk Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text: str, chunk_size: int = 2000, chunk_overlap: int = 300) -> list[str]:\n",
    "    \"\"\"\n",
    "    Splits text into smaller overlapping chunks using LangChain's text splitter.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        print(\"Warning: No text provided for splitting.\")\n",
    "        return []\n",
    "\n",
    "    if len(text) <= chunk_size:\n",
    "        return [text]  # If text is smaller than chunk size, return as single chunk\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, \n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "# Split the extracted text\n",
    "text_chunks = split_text_into_chunks(pdf_text)\n",
    "\n",
    "# Print the number of chunks and a sample chunk\n",
    "print(f\"Total chunks: {len(text_chunks)}\\nFirst chunk:\\n{text_chunks[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant Chunk Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector-based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embeddings \n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store text chunks into FAISS vector store\n",
    "vectorstore = FAISS.from_texts(text_chunks, embeddings)\n",
    "\n",
    "print(f\"Stored {len(text_chunks)} chunks in FAISS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define entities of interest that you'd like to extract chunks for from the vector store\n",
    "entities_of_interest = [\"unique accident\", \"accident type\", \"date\", \"time\", \"country\", \"regulatory body\"]\n",
    "\n",
    "# Function for extracting most relevant chunks from vector store\n",
    "def find_most_relevant_chunks(entities: list[str], top_k: int) -> str:\n",
    "    \"\"\"\n",
    "    Finds the most relevant text chunks for each entity of interest\n",
    "    using FAISS similarity search and removes duplicates (if same chunk retrieved).\n",
    "    \n",
    "    Args:\n",
    "    - entities (list): List of entity names to query (e.g., [\"date\", \"location\"])\n",
    "    - top_k (int): Number of chunks to retrieve per entity\n",
    "    \n",
    "    Returns:\n",
    "    - unique_relevant_chunks (list): Deduplicated relevant chunks\n",
    "    \"\"\"\n",
    "    retrieved_chunks = set()  # Use a set to avoid duplicate chunks\n",
    "\n",
    "    for entity in entities:\n",
    "        print(f\"Searching for entity: {entity}\")\n",
    "        query = f\"Report details about {entity}.\"\n",
    "        found_chunks = vectorstore.similarity_search(query, k=top_k)\n",
    "\n",
    "        for chunk in found_chunks:\n",
    "            retrieved_chunks.add(chunk.page_content)  # Add chunk if not already present\n",
    "\n",
    "    # Convert set back to a list and join into a single string\n",
    "    unique_relevant_chunks = list(retrieved_chunks)\n",
    "    combined_text = \"\\n\".join(unique_relevant_chunks)\n",
    "\n",
    "    print(f\"\\nFound {len(unique_relevant_chunks)} unique relevant chunks.\")\n",
    "    return combined_text\n",
    "\n",
    "# Find & combine relevant chunks\n",
    "relevant_text = find_most_relevant_chunks(entities_of_interest, top_k=3)\n",
    "\n",
    "print(f\"\\nMost Relevant Chunks Combined:\\n{relevant_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the API key and model name\n",
    "MODEL_GPT = \"gpt-4o-mini\"\n",
    "\n",
    "# Load OpenAI API Key from requirements file\n",
    "with open(\"gpt-personal-key.txt\", \"r\") as file:\n",
    "    OPENAI_API_KEY = file.read().strip()\n",
    "\n",
    "# Instantiate OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating tokens\n",
    "def count_tokens(text: str, model: str = \"gpt-4o\") -> int:\n",
    "    \"\"\"Efficiently counts tokens in a text for a given OpenAI model.\"\"\"\n",
    "    if model not in count_tokens.encoders:\n",
    "        count_tokens.encoders[model] = tiktoken.encoding_for_model(model)\n",
    "    return len(count_tokens.encoders[model].encode(text))\n",
    "\n",
    "count_tokens.encoders = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes for the entities extraction\n",
    "class Property(BaseModel):\n",
    "    \"\"\"A single property consisting of key and value.\"\"\"\n",
    "    key: str = Field(..., description=\"Property key\")\n",
    "    value: str = Field(..., description=\"Property value\")\n",
    "\n",
    "class Node(BaseNode):\n",
    "    \"\"\"Represents an entity in the railway accident knowledge graph.\"\"\"\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of node properties\")\n",
    "\n",
    "class Relationship(BaseRelationship):\n",
    "    \"\"\"Represents a relationship between two entities in the graph.\"\"\"\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of relationship properties\"\n",
    "    )\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"A knowledge graph storing railway accident data.\"\"\"\n",
    "    nodes: List[Node] = Field(\n",
    "        ..., description=\"List of nodes in the knowledge graph\")\n",
    "    rels: List[Relationship] = Field(\n",
    "        ..., description=\"List of relationships in the knowledge graph\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to call GPT model with respective prompt\n",
    "def call_gpt(prompt, temperature=1):\n",
    "    \"\"\"\n",
    "    Calls the GPT model with the structured prompt and returns the raw response.\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in analyzing railway accident reports. Return output in JSON format only.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    response_text = completion.choices[0].message.content.strip()\n",
    "    response_text = re.sub(r'^```json\\n?|```$', '', response_text).strip()\n",
    "    \n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gpt_prompt(text):\n",
    "    \"\"\"\n",
    "    Constructs a structured prompt to extract entities and relationships for railway accidents.\n",
    "    \"\"\"\n",
    "    \n",
    "    schema_example = \"\"\"\n",
    "    {\n",
    "        \"nodes\": [\n",
    "            {\"id\": \"Dublin-Cork Accident\", \"type\": \"UniqueAccident\"},\n",
    "            {\"id\": \"Train Derailment\", \"type\": \"AccidentType\"},\n",
    "            {\"id\": \"23/12/2021\", \"type\": \"Date\"},\n",
    "            {\"id\": \"16:32\", \"type\": \"Time\"},\n",
    "            {\"id\": \"Ireland\", \"type\": \"Country\"},\n",
    "            {\"id\": \"European Rail Agency\", \"type\": \"RegulatoryBody\"}\n",
    "        ],\n",
    "        \"rels\": [\n",
    "            {\"source\": \"Dublin-Cork Accident\", \"target\": \"Ireland\", \"type\": \"occurred_in\"},\n",
    "            {\"source\": \"Dublin-Cork Accident\", \"target\": \"\", \"type\": \"is_type\"},\n",
    "            {\"source\": \"Dublin-Cork Accident\", \"target\": \"European Rail Agency\", \"type\": \"investigated_by\"},\n",
    "            {\"source\": \"Dublin-Cork Accident\", \"target\": \"23/12/2021\", \"type\": \"has_date\"},\n",
    "            {\"source\": \"Dublin-Cork Accident\", \"target\": \"16:32\", \"type\": \"has_time\"}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    return f\"\"\"\n",
    "    Analyze the following railway accident report context and extract structured knowledge.\n",
    "\n",
    "    Return a JSON object with:\n",
    "    - `nodes`: A list of entities, specifically {entities_of_interest}.\n",
    "    - `rels`: A list of relationships linking entities.\n",
    "\n",
    "    Look at the JSON schema example response and follow it closely. Pay attention to date and type formats (e.g., EU date format, 24-hour time).\n",
    "    Ensure that the `source` and `target` nodes in `rels` are the same entities from the `nodes` list, and not different ones. \n",
    "    Make sure to map all nodes with other important entities, e.g., (node UniqueAccident has_date node Date, node UniqueAccident occurred_at node Country).\n",
    "    DO NOT map entities like (node Date is_date to node Time) or (node AccidentType is_type to node Country). This is incorrect.\n",
    "    The `type` field in `rels` should be a verb phrase (e.g., \"occurred_in\", \"investigated_by\").\n",
    "    And the `id` field in `nodes` should be the exact text of the entity, not a description or a summary.\n",
    "\n",
    "    Schema example:\n",
    "    {schema_example}\n",
    "\n",
    "    Accident report context:\n",
    "    {text}\n",
    "\n",
    "    JSON:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_knowledge_graph(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extracts entities & relationships from a railway accident report using GPT.\n",
    "    - First, counts tokens and allows user decision.\n",
    "    - If within limit, runs GPT and handles errors.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build prompt\n",
    "    prompt = build_gpt_prompt(text)\n",
    "\n",
    "    # Call GPT\n",
    "    response_text = call_gpt(prompt)\n",
    "\n",
    "    try:\n",
    "        extracted_graph = json.loads(response_text)  # Ensure valid JSON\n",
    "        return extracted_graph  # Successfully parsed knowledge graph\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error parsing JSON:\", str(e))\n",
    "        print(\"Storing raw response for review...\")\n",
    "\n",
    "        # Save the faulty response for debugging\n",
    "        with open(\"failed_graph_extractions.json\", \"a\") as file:\n",
    "            json.dump({\"input_text\": text[:1000], \"raw_output\": response_text}, file, indent=4)\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "        return {}  # Return empty dictionary in case of failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define token limit for function execution\n",
    "token_limit = 4096\n",
    "\n",
    "# Build the prompt and count tokens\n",
    "prompt = build_gpt_prompt(relevant_text)\n",
    "token_count = count_tokens(prompt)\n",
    "estimated_cost = token_count * 0.00000015  # Approximate OpenAI pricing\n",
    "\n",
    "# Check token limit\n",
    "if token_count > token_limit:\n",
    "    print(f\"Token count is too high: {token_count}\\nPlease reduce the chunk size or refine the prompt.\")\n",
    "    print(f\"Estimated cost: ${estimated_cost:.5f}\")\n",
    "else:\n",
    "    print(f\"Token count for prompt: {token_count}\")\n",
    "    print(f\"Estimated cost: ${estimated_cost:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm Execution\n",
    "proceed = input(\"Do you want to proceed with information extraction? (yes/no): \").strip().lower()\n",
    "if proceed != \"yes\":\n",
    "    print(\"Extraction aborted by user.\")\n",
    "else:\n",
    "    print(\"Sending request to GPT...\")\n",
    "    gpt_response = extract_knowledge_graph(relevant_text)\n",
    "    response_dict = {\"model\": MODEL_GPT, \"response\": gpt_response}\n",
    "    \n",
    "gpt_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating Local Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_local_prompt(text):\n",
    "    \"\"\"\n",
    "    Constructs a structured prompt to extract entities and relationships for railway accidents.\n",
    "    \"\"\"\n",
    "    \n",
    "    schema_example = \"\"\"\n",
    "    {\n",
    "        \"nodes\": [\n",
    "            {\"id\": \"Dublin-Cork Accident\", \"type\": \"UniqueAccident\"},\n",
    "            {\"id\": \"Train Derailment\", \"type\": \"AccidentType\"},\n",
    "            {\"id\": \"23/12/2021\", \"type\": \"Date\"},\n",
    "            {\"id\": \"16:32\", \"type\": \"Time\"},\n",
    "            {\"id\": \"Ireland\", \"type\": \"Country\"},\n",
    "            {\"id\": \"European Rail Agency\", \"type\": \"RegulatoryBody\"}\n",
    "        ],\n",
    "        \"rels\": [\n",
    "            {\"source\": \"Dublin-Cork Accident\", \"target\": \"Ireland\", \"type\": \"occurred_in\"},\n",
    "            {\"source\": \"Dublin-Cork Accident\", \"target\": \"\", \"type\": \"is_type\"},\n",
    "            {\"source\": \"Dublin-Cork Accident\", \"target\": \"European Rail Agency\", \"type\": \"investigated_by\"},\n",
    "            {\"source\": \"Dublin-Cork Accident\", \"target\": \"23/12/2021\", \"type\": \"has_date\"},\n",
    "            {\"source\": \"Dublin-Cork Accident\", \"target\": \"16:32\", \"type\": \"has_time\"}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    return f\"\"\"\n",
    "    Extract structured entities and output ONLY a JSON object from this railway accident report. Do not provide a summary or comment on the incident.\n",
    "\n",
    "    Return the JSON object with:\n",
    "    - `nodes`: A list of entities, specifically {entities_of_interest}.\n",
    "    - `rels`: A list of relationships linking entities.\n",
    "\n",
    "    Schema example:\n",
    "    {schema_example}\n",
    "\n",
    "    Accident report context:\n",
    "    {text}\n",
    "\n",
    "    JSON:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API URL\n",
    "url = \"http://llama-max-ollama.ai.wu.ac.at/api/generate\"\n",
    "\n",
    "# Define prompt\n",
    "prompt = build_local_prompt(relevant_text)\n",
    "\n",
    "# Specify local model\n",
    "MODEL_LOCAL = \"llama3.1:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the payload and query the local model\n",
    "payload = {\n",
    "    \"model\": f\"{MODEL_LOCAL}\",  # Ensure correct model name\n",
    "    \"prompt\": f\"{prompt}\",\n",
    "    \"stream\": False  # If 'raw' is unnecessary, remove it\n",
    "}\n",
    "\n",
    "# Set headers\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Send POST request\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "# Handle response\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        data = response.json()  # Parse response JSON\n",
    "        if \"response\" in data:\n",
    "            local_response = textwrap.fill(data[\"response\"], width=80)\n",
    "            print(\"Generated Summary:\\n\")\n",
    "            print(local_response)\n",
    "        else:\n",
    "            print(\"No 'response' key found in the JSON.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Invalid JSON response: {response.text}\")\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(text):\n",
    "    # List of regex patterns to try.\n",
    "    patterns = [\n",
    "        # Pattern for JSON wrapped in a markdown code block:\n",
    "        r'```json\\s*([\\s\\S]*?)\\s*```',\n",
    "        # Fallback pattern: JSON object starting with '{' and ending with '}'\n",
    "        r'({[\\s\\S]*})'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            json_str = match.group(1)\n",
    "            # Optionally, remove unwanted control characters.\n",
    "            json_str = re.sub(r'[\\x00-\\x1F]+', '', json_str)\n",
    "            try:\n",
    "                return json.loads(json_str)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(\"JSON decode error:\", e)\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "local_response = extract_json(local_response)\n",
    "response_dict = {\"model\": MODEL_LOCAL, \"response\": local_response}\n",
    "local_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-model and Iteration Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CSV storage file\n",
    "CSV_FILE = \"pdf_processing_results.csv\"\n",
    "\n",
    "def append_pdf_json_result(pdf_name: str, response_json: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Appends the JSON output of response_json function to a DataFrame.\n",
    "    \n",
    "    - If the PDF has been processed before, it appends a **new row** instead of a new column.\n",
    "    - Prevents duplicate JSON entries for the same iteration.\n",
    "    - Ensures data is **stored in rows**, making querying and analysis easier.\n",
    "\n",
    "    Args:\n",
    "        pdf_name (str): Name of the processed PDF file.\n",
    "        response_json (dict): JSON response from the knowledge extraction process.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with the new result.\n",
    "    \"\"\"\n",
    "    # Convert JSON response to a formatted string for easy comparison\n",
    "    json_output = json.dumps(response_json, indent=2)\n",
    "\n",
    "    # Load existing results if the CSV exists\n",
    "    if os.path.exists(CSV_FILE):\n",
    "        df = pd.read_csv(CSV_FILE, dtype={\"iteration_number\": int})\n",
    "    else:\n",
    "        # Create an empty DataFrame with the correct schema\n",
    "        df = pd.DataFrame(columns=[\"pdf_name\", \"model_type\", \"iteration_number\", \"json_output\"])\n",
    "\n",
    "    model_type = MODEL_GPT if response_dict.get(\"model\") == MODEL_GPT else MODEL_LOCAL\n",
    "\n",
    "    # Filter for the current PDF's past records\n",
    "    pdf_history = df[df[\"pdf_name\"] == pdf_name]\n",
    "\n",
    "    # Check for duplicates: If this JSON output already exists for the same PDF, skip re-adding\n",
    "    if not pdf_history.empty and json_output in pdf_history[\"json_output\"].values:\n",
    "        print(f\"No changes detected in JSON for {pdf_name}, skipping new entry.\")\n",
    "        return df  # Exit early if it's a duplicate\n",
    "\n",
    "    # Determine new iteration number\n",
    "    iteration_number = pdf_history[\"iteration_number\"].max() + 1 if not pdf_history.empty else 1\n",
    "\n",
    "    # Append new result\n",
    "    new_entry = pd.DataFrame({\"pdf_name\": [pdf_name], \"model_type\": [model_type], \"iteration_number\": [iteration_number], \"json_output\": [json_output]})\n",
    "    df = pd.concat([df, new_entry], ignore_index=True)\n",
    "\n",
    "    # Save back to CSV in **append mode** to avoid full file reads/writes\n",
    "    df.to_csv(CSV_FILE, index=False)\n",
    "\n",
    "    print(f\"Successfully added {pdf_name} - Iteration {iteration_number} to results!\")\n",
    "    return df\n",
    "\n",
    "# Example execution\n",
    "results_df = append_pdf_json_result(pdf_name, response_dict[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions for mapping extracted entities to graph nodes and relationships\n",
    "def props_to_dict(props) -> dict:\n",
    "    \"\"\"Converts properties to a dictionary for graph storage.\"\"\"\n",
    "    properties = {}\n",
    "    if not props:\n",
    "        return properties\n",
    "    for p in props:\n",
    "        properties[p[\"key\"]] = p[\"value\"]\n",
    "    return properties\n",
    "\n",
    "def map_to_base_node(node: Node) -> BaseNode:\n",
    "    \"\"\"Maps extracted entities to graph nodes.\"\"\"\n",
    "    properties = {\"name\": node.id}\n",
    "    return BaseNode(\n",
    "        id=node.id,\n",
    "        type=node.type.capitalize(),\n",
    "        properties=properties\n",
    "    )\n",
    "\n",
    "def map_to_base_relationship(rel: Relationship) -> BaseRelationship:\n",
    "    \"\"\"Maps extracted relationships to graph edges.\"\"\"\n",
    "    source = map_to_base_node(rel.source)\n",
    "    target = map_to_base_node(rel.target)\n",
    "    properties = props_to_dict(rel.properties) if rel.properties else {}\n",
    "\n",
    "    return BaseRelationship(\n",
    "        source=source, target=target, type=rel.type, properties=properties\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j Connection Setup\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"password\"\n",
    "NEO4J_DATABASE = \"neo4j\"\n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "try:\n",
    "    # Test the connection\n",
    "    with driver.session() as session:\n",
    "        session.run(\"RETURN 1\")\n",
    "    print(\"Connected to Neo4j successfully.\")\n",
    "except AuthError as e:\n",
    "    print(\"Authentication failed. Check your credentials:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear database\n",
    "def clear_neo4j_database():\n",
    "    \"\"\"Delete all nodes and relationships in the Neo4j database.\"\"\"\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "    print(\"Neo4j database cleared successfully.\")\n",
    "\n",
    "# Run the function to clear the database\n",
    "clear_neo4j_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_output(df, pdf_name, iteration_number):\n",
    "    \"\"\"\n",
    "    Gets the 'json_output' for the given pdf_name and iteration_number.\n",
    "    Returns an empty dict if there's no match.\n",
    "    \"\"\"\n",
    "    subset = df[\n",
    "        (df[\"pdf_name\"] == pdf_name) &\n",
    "        (df[\"iteration_number\"] == iteration_number)\n",
    "    ]\n",
    "\n",
    "    if subset.empty:\n",
    "        print(\"No match found.\")\n",
    "        return {}\n",
    "\n",
    "    json_str = subset.iloc[0][\"json_output\"]\n",
    "    return json.loads(json_str)\n",
    "\n",
    "# Example usage:\n",
    "pdf_of_choice = \"IE-6305 - 200707_locomotive_224.pdf\"\n",
    "json_to_convert = get_json_output(results_df, pdf_of_choice, 1)\n",
    "print(json.dumps(json_to_convert, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_graph(json_to_convert, source_text):\n",
    "    \"\"\"\n",
    "    Converts extracted JSON into a graph-compatible format with correct entity types.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_node_type(json_data, node_id):\n",
    "        \"\"\"\n",
    "        Helper function to retrieve the correct node type from JSON.\n",
    "        \"\"\"\n",
    "        for node in json_data[\"nodes\"]:\n",
    "            if node[\"id\"] == node_id:\n",
    "                return node[\"type\"]\n",
    "        return \"Unknown\"  # Fallback if type is missing\n",
    "\n",
    "    if not json_to_convert:\n",
    "        print(\"No valid data to convert to a graph.\")\n",
    "        return None\n",
    "\n",
    "    # Convert Nodes\n",
    "    graph_nodes = [map_to_base_node(Node(id=node[\"id\"], type=node[\"type\"])) for node in json_to_convert[\"nodes\"]]\n",
    "\n",
    "    # Convert Relationships (Ensure correct types)\n",
    "    graph_rels = []\n",
    "    for rel in json_to_convert[\"rels\"]:\n",
    "        source_node = Node(id=rel[\"source\"], type=get_node_type(json_to_convert, rel[\"source\"]))\n",
    "        target_node = Node(id=rel[\"target\"], type=get_node_type(json_to_convert, rel[\"target\"]))\n",
    "        graph_rels.append(map_to_base_relationship(Relationship(source=source_node, target=target_node, type=rel[\"type\"])))\n",
    "\n",
    "    return GraphDocument(nodes=graph_nodes, relationships=graph_rels, source=Document(page_content=source_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_in_neo4j(graph_document):\n",
    "    \"\"\"\n",
    "    Stores extracted knowledge graph into Neo4j with dynamic labels.\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        # Store nodes with dynamic labels\n",
    "        for node in graph_document.nodes:\n",
    "            session.run(f\"\"\"\n",
    "                MERGE (n:{node.type} {{id: $id}})\n",
    "                ON CREATE SET n.name = $name\n",
    "            \"\"\", id=node.id, name=node.id)\n",
    "\n",
    "        # Store relationships\n",
    "        for rel in graph_document.relationships:\n",
    "            session.run(f\"\"\"\n",
    "                MATCH (s {{id: $source}})\n",
    "                MATCH (t {{id: $target}})\n",
    "                MERGE (s)-[r:{rel.type.upper()}]->(t)\n",
    "            \"\"\", source=rel.source.id, target=rel.target.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_railway_accident_report(json_to_convert):\n",
    "    \"\"\"\n",
    "    Converts the JSON to a graph format and stores it in Neo4j.\n",
    "    \"\"\"\n",
    "    print(\"Converting JSON to graph format...\")\n",
    "    graph_document = convert_json_to_graph(json_to_convert, relevant_text)\n",
    "\n",
    "    if graph_document:\n",
    "        print(\"Graph structure created! Storing in Neo4j...\")\n",
    "        store_in_neo4j(graph_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store extracted entities into Neo4j\n",
    "try:\n",
    "    db_result = process_railway_accident_report(json_to_convert)\n",
    "    print(\"Data stored in Neo4j successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to store data in Neo4j:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Neo4j connection\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison against ERAIL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ERAIL DB\n",
    "erail_db = pd.read_excel(\"erail database.xlsx\")\n",
    "\n",
    "erail_db.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime & adjust format\n",
    "erail_db[\"Date of occurrence\"] = erail_db[\"Date of occurrence\"].dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "# Convert time column to datetime & adjust format\n",
    "erail_db[\"Time of occurrence\"] = pd.to_datetime(erail_db[\"Time of occurrence\"], errors='coerce')\n",
    "erail_db[\"Time of occurrence\"] = erail_db[\"Time of occurrence\"].dt.strftime(\"%H:%M\")\n",
    "\n",
    "erail_db.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the results DataFrame\n",
    "comparison_df = results_df[[\"pdf_name\", \"json_output\"]].copy()\n",
    "\n",
    "# Extract ID from the PDF name\n",
    "comparison_df[\"ERAIL Occurrence\"] = comparison_df[\"pdf_name\"].str.extract(r'(IE-\\d+)')\n",
    "\n",
    "# Sample DataFrame (assuming json_output column contains dictionaries in string format)\n",
    "comparison_df['json_output'] = comparison_df['json_output'].apply(json.loads)  # Convert JSON string to dictionary\n",
    "\n",
    "# Function to extract node data\n",
    "def extract_nodes(json_data):\n",
    "    node_dict = {}\n",
    "    for node in json_data.get(\"nodes\", []):\n",
    "        node_dict[f\"gpt_{node['type']}\"] = node[\"id\"]  # Store ID based on type\n",
    "    return pd.Series(node_dict)  # Convert dictionary to Series for easier DataFrame merging\n",
    "\n",
    "# Apply the function to extract node data\n",
    "nodes_df = comparison_df['json_output'].apply(extract_nodes)\n",
    "\n",
    "# Merge extracted data into original DataFrame\n",
    "comparison_df = pd.concat([comparison_df, nodes_df], axis=1)\n",
    "\n",
    "# Drop the original json_output column if no longer needed\n",
    "comparison_df.drop(columns=[\"json_output\"], inplace=True)\n",
    "\n",
    "# View comparison DataFrame\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the comparison DataFrame with the ERAIL database\n",
    "merged_df = comparison_df.merge(erail_db, on=\"ERAIL Occurrence\", how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare GPT extracted date with the ERAIL database (source of truth)\n",
    "merged_df[\"Date Match\"] = np.where(merged_df[\"gpt_Date\"] == merged_df[\"Date of occurrence\"], \"Match\", \"Mismatch\")\n",
    "merged_df[[\"ERAIL Occurrence\", \"gpt_Date\", \"Date of occurrence\", \"Date Match\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare GPT extracted time with the ERAIL database (source of truth)\n",
    "merged_df[\"Time Match\"] = np.where(merged_df[\"gpt_Time\"] == merged_df[\"Time of occurrence\"], \"Match\", \"Mismatch\")\n",
    "merged_df[[\"ERAIL Occurrence\", \"gpt_Time\", \"Time of occurrence\", \"Time Match\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare GPT extracted country with the ERAIL database (source of truth)\n",
    "merged_df[\"Country Match\"] = np.where(merged_df[\"gpt_Country\"] == merged_df[\"Country\"], \"Match\", \"Mismatch\")\n",
    "merged_df[[\"ERAIL Occurrence\", \"gpt_Country\", \"Country\", \"Country Match\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

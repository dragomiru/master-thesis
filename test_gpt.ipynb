{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\software\\miniconda\\envs\\master_thesis\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\software\\miniconda\\envs\\master_thesis\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\software\\miniconda\\envs\\master_thesis\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\software\\miniconda\\envs\\master_thesis\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\software\\miniconda\\envs\\master_thesis\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\software\\miniconda\\envs\\master_thesis\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 894.9/894.9 kB 39.5 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General \n",
    "import os\n",
    "\n",
    "# PDFs\n",
    "import pdfplumber\n",
    "import json\n",
    "import regex as re\n",
    "\n",
    "# LLMs\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import tiktoken\n",
    "\n",
    "# Neo4j\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import AuthError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating GPT & Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-mini\"\n",
    "\n",
    "# Load OpenAI API Key from requirements file\n",
    "with open(\"gpt-personal-key.txt\", \"r\") as file:\n",
    "    OPENAI_API_KEY = file.read().strip()\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceUnavailable",
     "evalue": "Couldn't connect to localhost:7687 (resolved to ('[::1]:7687', '127.0.0.1:7687')):\nFailed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\nFailed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32md:\\Software\\Miniconda\\envs\\master_thesis\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:409\u001b[0m, in \u001b[0;36mBoltSocketBase._connect_secure\u001b[1;34m(cls, resolved_address, timeout, keep_alive, ssl_context)\u001b[0m\n\u001b[0;32m    408\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  C: <OPEN> \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, resolved_address)\n\u001b[1;32m--> 409\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m s\u001b[38;5;241m.\u001b[39msettimeout(t)\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32md:\\Software\\Miniconda\\envs\\master_thesis\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt_socket.py:328\u001b[0m, in \u001b[0;36mBoltSocket.connect\u001b[1;34m(cls, address, tcp_timeout, deadline, custom_resolver, ssl_context, keep_alive)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 328\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect_secure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtcp_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssl_context\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m     agreed_version, handshake, response \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39m_handshake(\n\u001b[0;32m    332\u001b[0m         resolved_address, deadline\n\u001b[0;32m    333\u001b[0m     )\n",
      "File \u001b[1;32md:\\Software\\Miniconda\\envs\\master_thesis\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:426\u001b[0m, in \u001b[0;36mBoltSocketBase._connect_secure\u001b[1;34m(cls, resolved_address, timeout, keep_alive, ssl_context)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;167;01mOSError\u001b[39;00m):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\n\u001b[0;32m    427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish connection to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_address\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m (reason \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merror\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m: Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Test the connection\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m driver\u001b[38;5;241m.\u001b[39msession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 12\u001b[0m         \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRETURN 1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnected to Neo4j successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AuthError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Software\\Miniconda\\envs\\master_thesis\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:313\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result\u001b[38;5;241m.\u001b[39m_buffer_all()\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection:\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_access_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    315\u001b[0m cx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\n",
      "File \u001b[1;32md:\\Software\\Miniconda\\envs\\master_thesis\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:136\u001b[0m, in \u001b[0;36mSession._connect\u001b[1;34m(self, access_mode, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     access_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdefault_access_mode\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43macquire_kwargs\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_cancellation(message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_connect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Software\\Miniconda\\envs\\master_thesis\\Lib\\site-packages\\neo4j\\_sync\\work\\workspace.py:199\u001b[0m, in \u001b[0;36mWorkspace._connect\u001b[1;34m(self, access_mode, auth, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m acquire_kwargs_ \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: access_mode,\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: acquisition_timeout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_db_resolution_callback(),\n\u001b[0;32m    197\u001b[0m }\n\u001b[0;32m    198\u001b[0m acquire_kwargs_\u001b[38;5;241m.\u001b[39mupdate(acquire_kwargs)\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43macquire_kwargs_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    201\u001b[0m     target_db\u001b[38;5;241m.\u001b[39mguessed\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pinned_database\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;66;03m# support SSR.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# => we need to fall back to explicit home database resolution\u001b[39;00m\n\u001b[0;32m    208\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <WORKSPACE> detected ssr support race; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalling back to explicit home database resolution\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m     )\n",
      "File \u001b[1;32md:\\Software\\Miniconda\\envs\\master_thesis\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:662\u001b[0m, in \u001b[0;36mBoltPool.acquire\u001b[1;34m(self, access_mode, timeout, database, bookmarks, auth, liveness_check_timeout, database_callback)\u001b[0m\n\u001b[0;32m    655\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <POOL> acquire direct connection, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_mode=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m, database=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    658\u001b[0m     access_mode,\n\u001b[0;32m    659\u001b[0m     database,\n\u001b[0;32m    660\u001b[0m )\n\u001b[0;32m    661\u001b[0m deadline \u001b[38;5;241m=\u001b[39m Deadline\u001b[38;5;241m.\u001b[39mfrom_timeout_or_deadline(timeout)\n\u001b[1;32m--> 662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mliveness_check_timeout\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Miniconda\\envs\\master_thesis\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:408\u001b[0m, in \u001b[0;36mIOPool._acquire\u001b[1;34m(self, address, auth, deadline, liveness_check_timeout)\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ClientError(\n\u001b[0;32m    404\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed to obtain a connection from the pool within \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    405\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeadline\u001b[38;5;241m.\u001b[39moriginal_timeout\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124ms (timeout)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    406\u001b[0m             )\n\u001b[0;32m    407\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <POOL> trying to hand out new connection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Miniconda\\envs\\master_thesis\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:230\u001b[0m, in \u001b[0;36mIOPool._acquire_new_later.<locals>.connection_creator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m         connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopener\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m            \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ServiceUnavailable:\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeactivate(address)\n",
      "File \u001b[1;32md:\\Software\\Miniconda\\envs\\master_thesis\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:624\u001b[0m, in \u001b[0;36mBoltPool.open.<locals>.opener\u001b[1;34m(addr, auth_manager, deadline)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mopener\u001b[39m(addr, auth_manager, deadline):\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBolt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrouting_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Software\\Miniconda\\envs\\master_thesis\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:369\u001b[0m, in \u001b[0;36mBolt.open\u001b[1;34m(cls, address, auth_manager, deadline, routing_context, pool_config)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deadline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m Deadline(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 369\u001b[0m s, protocol_version, handshake, data \u001b[38;5;241m=\u001b[39m \u001b[43mBoltSocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtcp_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_resolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ssl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m pool_config\u001b[38;5;241m.\u001b[39mprotocol_version \u001b[38;5;241m=\u001b[39m protocol_version\n\u001b[0;32m    379\u001b[0m protocol_handlers \u001b[38;5;241m=\u001b[39m Bolt\u001b[38;5;241m.\u001b[39mprotocol_handlers\n",
      "File \u001b[1;32md:\\Software\\Miniconda\\envs\\master_thesis\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt_socket.py:376\u001b[0m, in \u001b[0;36mBoltSocket.connect\u001b[1;34m(cls, address, tcp_timeout, deadline, custom_resolver, ssl_context, keep_alive)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     error_strs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, errors))\n\u001b[1;32m--> 376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddress\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (resolved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddress_strs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror_strs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    379\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merrors\u001b[39;00m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m: Couldn't connect to localhost:7687 (resolved to ('[::1]:7687', '127.0.0.1:7687')):\nFailed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\nFailed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)"
     ]
    }
   ],
   "source": [
    "# Neo4j Connection Setup\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"password\"\n",
    "NEO4J_DATABASE = \"neo4j\"\n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "try:\n",
    "    # Test the connection\n",
    "    with driver.session() as session:\n",
    "        session.run(\"RETURN 1\")\n",
    "    print(\"Connected to Neo4j successfully.\")\n",
    "except AuthError as e:\n",
    "    print(\"Authentication failed. Check your credentials:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j database cleared successfully.\n"
     ]
    }
   ],
   "source": [
    "def clear_neo4j_database():\n",
    "    \"\"\"Delete all nodes and relationships in the Neo4j database.\"\"\"\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "    print(\"Neo4j database cleared successfully.\")\n",
    "\n",
    "# Run the function to clear the database\n",
    "clear_neo4j_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a given PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Test PDF extraction\n",
    "pdf_text = extract_text_from_pdf(\"raiu_example.pdf\")\n",
    "print(pdf_text[:500])  # Print first 500 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processed Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1:\n",
      "Railway Accident\n",
      "Investigation Unit\n",
      "Ireland\n",
      "INVESTIGATION REPORT\n",
      "Broken Rail near Emly,\n",
      "County Tipperary, 22nd February 2023\n",
      "RAIU Investigation Report No: 2024-R002\n",
      "Published: 22nd March 2024\n",
      "----------------------------------------\n",
      "Page 2:\n",
      "Broken Rail near Emly, County Tipperary, 22nd February 2023\n",
      "Report Description\n",
      "Report publication\n",
      "This report is published by the Railway Accident Investigation Unit (RAIU). The copyright in\n",
      "the enclosed report remains with the RAIU by virtue of in Regulation 9 (7) of European Union\n",
      "(EU) (Railway Safety) (Reporting and Investigation of Serious Accidents, Accidents and\n",
      "Incidents) Regulations 2020 (S.I. 430 of 2020). No person may produce, reproduce or transmit\n",
      "in any form or by any means this rep\n",
      "----------------------------------------\n",
      "Page 3:\n",
      "Broken Rail near Emly, County Tipperary, 22nd February 2023\n",
      "Preface\n",
      "The RAIU is an independent investigation unit within the Department of Transport which\n",
      "conducts investigations into accidents and incidents on the national railway network including\n",
      "the Dublin Area Rapid Transit (DART) network, the LUAS light rail system, heritage and\n",
      "industrial railways in Ireland. Investigations are carried out in accordance with the Railway\n",
      "Safety Directive (EU) 2016/798 enshrined in the European Union (Railw\n",
      "----------------------------------------\n",
      "Page 4:\n",
      "Broken Rail near Emly, County Tipperary, 22nd February 2023\n",
      "Contents\n",
      "Summary .............................................................................................................................. 1\n",
      "RAIU Investigation and its context......................................................................................... 6\n",
      "Decision & motivation to investigate this occurrence. ...................................................... 6\n",
      "Scope & limits of investigation .........................\n",
      "----------------------------------------\n",
      "Page 5:\n",
      "Broken Rail near Emly, County Tipperary, 22nd February 2023\n",
      "Previous occurrences in previous ten years .................................................................. 30\n",
      "Analysis .............................................................................................................................. 31\n",
      "Mechanism of failure ..................................................................................................... 31\n",
      "Actions by members of staff on-site during Thermit SoW-5 .....\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF while allowing for pre-processing.\n",
    "    \"\"\"\n",
    "    text = []\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text.append(page_text)\n",
    "    \n",
    "    return text  # Returns a list where each item is a page's text\n",
    "\n",
    "# Extract pages as a list\n",
    "pdf_pages = extract_text_from_pdf(\"raiu_example.pdf\")\n",
    "\n",
    "# Print the first few pages to inspect where the TOC might be\n",
    "for i, page in enumerate(pdf_pages[:5]):  # Check first 5 pages\n",
    "    print(f\"Page {i+1}:\\n{page[:500]}\\n{'-'*40}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Railway Accident\n",
      "Investigation Unit\n",
      "Ireland\n",
      "INVESTIGATION REPORT\n",
      "Broken Rail near Emly,\n",
      "County Tipperary, 22nd February 2023\n",
      "RAIU Investigation Report No: 2024-R002\n",
      "Published: 22nd March 2024\n",
      "Broken Rail near Emly, County Tipperary, 22nd February 2023\n",
      "Report Description\n",
      "Report publication\n",
      "This report is published by the Railway Accident Investigation Unit (RAIU). The copyright in\n",
      "the enclosed report remains with the RAIU by virtue of in Regulation 9 (7) of European Union\n",
      "(EU) (Railway Safety) (Reporting and Investigation of Serious Accidents, Accidents and\n",
      "Incidents) Regulations 2020 (S.I. 430 of 2020). No person may produce, reproduce or transmit\n",
      "in any form or by any means this report or any part thereof without the express permission of\n",
      "the RAIU. This report may be freely used for educational purposes.\n",
      "Where the report has been altered following its original publication, details on the changes will\n",
      "be given.\n",
      "Report structure\n",
      "The report structure is written as closely as possible to the structure set out in the “Commission\n",
      "Implementation Regulation (EU) 2020/572 of 24 April 2020 on the reporting structure to be\n",
      "followed for railway accident and incident investigation reports” having regard to “Directive\n",
      "(EU) 2016/798 of the European Parliament and of the Council of 11 May 2016 on railway\n",
      "safety”.\n",
      "Reader guide\n",
      "All dimensions and speeds in this report are given using the International System of Units (SI\n",
      "Units). Where the normal railway practice, in some railway organisations, is to use imperial\n",
      "dimensions; imperial dimensions are used, and the SI Unit is also given.\n",
      "All abbreviations and technical terms (which appear in italics the first time they appear in the\n",
      "report) are explained in the glossary.\n",
      "Descriptions and figures may be simplified in order to illustrate concepts to non-technical\n",
      "readers.\n",
      "Further information\n",
      "For further information, or to contact the RAIU, please see details below:\n",
      "RAIU email: info@raiu.ie\n",
      "2nd Floor, 2 Leeson Lane website: www.raiu.ie\n",
      "Dublin 2, Ireland. telephone: + 353 1 604 1050\n",
      "Railway Accident Investigation Unit i\n",
      "Broken Rail near Emly, County Tipperary, 22nd February 2023\n",
      "Preface\n",
      "The RAIU is an independent investigation unit within the Department of Transport which\n",
      "conducts investigations into accidents and incidents on the national railway network including\n",
      "the Dublin Area Rapid Transit (DART) network, the LUAS light rail system, heritage and\n",
      "industrial railways in Ireland. Investigations are carried out in accordance with the Railway\n",
      "Safety Directive (EU) 2016/798 enshrined in the European Union (Railway Safety) (Reporting\n",
      "and Investigation of Serious Accidents, Accidents and Incidents) Regulations 2020; and,\n",
      "where relevant, by the application of the Railway Safety (Reporting and Investigation of\n",
      "Serious Accidents, Accidents and Incidents Involving Certain Railways) Act 2020.\n",
      "The RAIU investigate all serious accidents. A serious accident is defined as any train collision\n",
      "or derailment of trains, resulting in the death of at least one person or serious injuries to five\n",
      "or more persons or extensive damage to rolling stock, the infrastructure or the environment,\n",
      "and any other similar accident with an obvious impact on railway or tramline safety regulation\n",
      "or the management of safety. During an investigation, if the RAIU make some early findings\n",
      "on safety issues that require immediate action, the RAIU will issue an Urgent Safety Advice\n",
      "Notice outlining the associated safety recommendation(s); other issues may require a Safety\n",
      "Advice Notice.\n",
      "The RAIU may investigate and report on accidents and incidents which under slightly different\n",
      "conditions may have led to a serious accident.\n",
      "The RAIU may also carry out trend investigations where the occurrence is part of a group of\n",
      "related occurrences that may or may not have warranted an investigation as individual\n",
      "occurrences, but the apparent trend warrants investigation.\n",
      "The RAIU investigation shall analyse the established facts and findings (i.e. performance of\n",
      "operators, rolling stock and/or technical installations) which caused the occurrence. The\n",
      "analyses shall then lead to the identification of the safety critical factors that caused or\n",
      "otherwise contributed to the occurrence, including facts identified as precursors. An accident\n",
      "or incident may be caused by causal, contributing and systemic factors which are equally\n",
      "important and should be consider during the RAIU investigation. From this, the RAIU may\n",
      "make safety recommendations in order to prevent accidents and incidents in the future and\n",
      "improve railway safety.\n",
      "It is not the purpose of an RAIU investigation to attribute blame or liability.\n",
      "Railway Accident Investigation Unit ii\n",
      "Broken Rail near Emly, County Tipperary, 22nd February 2023\n",
      "Summary\n",
      "1 On Tuesday 21st February 2023 a T3 Possession was organised on the Up and Down\n",
      "lines of the Dublin to Cork mainline to allow for a track section, near Emly Level Crossing\n",
      "(LC), to undergo track maintenance.\n",
      "2 As part of the track maintenance, stressing and welding of the rails had to be undertaken\n",
      "in preparation for ballast cleaning.\n",
      "3 The stressing of the rails was being carried out on the Up line, which involved cutting both\n",
      "rails which was marked by a Iarnród Éireann Infrastructure Manager (IÉ-IM) staff member,\n",
      "the Person in Charge of Stressing (this member of IÉ-IM staff was also the Track Delivery\n",
      "Unit Engineer (TDU Engineer) who supervised the works).\n",
      "4 A welding contractor was engaged to carry out the welding at the site location (110 miles\n",
      "355 yards), with a team comprising of a lead and second welder (the Welders) and a Weld\n",
      "Supervisor. Prior to the welding, the Welders placed clamps on either side of the first cut\n",
      "rail section and attached Rail Tensors to pull the rail ends together until the required\n",
      "welders gap was achieved. The rails were then anchored by the Chief Civil Engineer’s\n",
      "(CCE) Department staff to ensure no movement of the rails, and the rail ends were welded\n",
      "using the Thermit® SoW-5 welding process (to be referred to as Thermit SoW-5 for the\n",
      "remainder of the report); the first weld was “dropped” without issue.\n",
      "5 The Welders then placed the clamps on either side of the next cut location and attached\n",
      "the Rail Tensors in order to pull the rails ends together. On the first attempt when pressure\n",
      "was applied by the Rail Tensors the rails did not hold; on the second attempt, the Rail\n",
      "Tensors failed to pull the rail ends together; but, on the third attempt, the rail ends were\n",
      "pulled to the required welders gap. The Welders then waited to make sure the Rail Tensors\n",
      "held and once they were sure it was holding, the CCE staff fastened down the tension\n",
      "clamps to anchor the rails and the Welders dropped the weld without further issue.\n",
      "6 The welds were inspected by the Weld Supervisor who was satisfied that there were no\n",
      "visible defects.\n",
      "7 When the welds had cooled, the Ultrasonic Operator tested the rails, which passed the\n",
      "ultrasonic tests with no defects identified.\n",
      "8 The T3 Possession was handed back by the Person In Charge of the Possession (PICOP)\n",
      "at 05:00 hours (hrs) on Tuesday the 21st February 2023 and normal service resumed on\n",
      "the Up line. A total of twenty-four passenger service trains passed the section on Tuesday\n",
      "and Wednesday morning until the fault was detected.\n",
      "Railway Accident Investigation Unit 1\n",
      "Broken Rail near Emly, County Tipperary, 22nd February 2023\n",
      "9 On Wednesday 22nd February 2023, at 07:56 hrs, the Signalman at Centralised Traffic\n",
      "Control (CTC) saw that a track circuit (LJ789 on the Up line, near Emly LC) remained\n",
      "occupied after the 07:00 hrs passenger service from Cork to Heuston (Train A205) passed\n",
      "through the location.\n",
      "10 The Signalman contacted the driver of Train A205 (Driver A205) to ensure the train had\n",
      "passed safely through the affected section of line.\n",
      "11 At 07:57 hrs the Signalman confirmed with Mallow Level Crossing Control Centre (LCCC)\n",
      "that there was no fault with the signalling equipment at Emly LC.\n",
      "12 At 07:59 hrs the Signalman contacted the Signal Electrical and Telecommunications (SET)\n",
      "Department to report the track circuit fault. SET staff members deployed to the location,\n",
      "and checked a number of SET location cases near the location of the fault; before walking\n",
      "the track and finding a broken rail, at the 110 miles 355 yards (the location of the welded\n",
      "rail), at 10:35 hrs.\n",
      "13 Just as the SET staff member had discovered the broken rail a train was approaching on\n",
      "the Up line. It was the 09:25 hrs passenger service from Cork to Heuston (Train A209)\n",
      "travelling under caution. The SET staff member stepped out to a position of safety and\n",
      "signalled the train to stop. Train A209 travelled over the broken rail before coming to a\n",
      "stop.\n",
      "14 The SET member spoke to the driver (Driver A209) and told them the fault was a broken\n",
      "rail and the train had travelled over it. Driver A209 notified the Signalman of the broken rail\n",
      "and resumed their journey.\n",
      "15 The Signalman contacted the SET staff member who confirmed that the track circuit fault\n",
      "was as a result of a broken rail.\n",
      "16 The Signalman took the appropriate actions and signal protection was put in place on the\n",
      "Up line.\n",
      "17 The Signalman contacted the Permanent Way Inspector (PWI) who confirmed that they\n",
      "had been notified of the broken rail. The PWI attended the site of the broken rail, and the\n",
      "rail was clamped and plated.\n",
      "18 The line re-opened at 11:30 hrs with an Emergency Speed Restriction (ESR) of 10 mph\n",
      "(16 km/h) in place until later that night, when the repairs were undertaken. The ESR was\n",
      "lifted, and normal passenger service resumed at 05:30 hrs on Thursday the 23rd February\n",
      "2023.\n",
      "Railway Accident Investigation Unit 2\n",
      "Broken Rail near Emly, County Tipperary, 22nd February 2023\n",
      "19 A post-incident metallurgical examination of the weld found that the weld broke rapidly\n",
      "from defects introduced during Thermit SoW-5. The position of the defects was within the\n",
      "last areas to solidify (the centre of the weld) with the appearance indicating that the defec\n"
     ]
    }
   ],
   "source": [
    "def extract_text_omit_toc(pdf_path, toc_start=4, toc_end=5):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF while skipping the Table of Contents.\n",
    "    \"\"\"\n",
    "    text = []\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            if toc_start <= i+1 <= toc_end:  # Skip TOC pages\n",
    "                continue\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text.append(page_text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Extract text without TOC\n",
    "filtered_pdf_pages = extract_text_omit_toc(\"raiu_example.pdf\")\n",
    "\n",
    "# Join pages into a single text document\n",
    "cleaned_text = \"\\n\".join(filtered_pdf_pages)\n",
    "print(cleaned_text[:10000])  # Preview the cleaned text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Railway Accident\n",
      "Investigation Unit\n",
      "INVESTIGATION REPORT\n",
      "Broken Rail near Emly,\n",
      "County Tipperary, 22nd February 2023\n",
      "RAIU Investigation Report No: 2024-R002\n",
      "Published: 22nd March 2024\n",
      "Report Description\n",
      "Report publication\n",
      "This report is published by the Railway Accident Investigation Unit (RAIU). The copyright in\n",
      "the enclosed report remains with the RAIU by virtue of in Regulation 9 (7) of European Union\n",
      "(EU) (Railway Safety) (Reporting and Investigation of Serious Accidents, Accidents and\n",
      "Incidents) Regulations 2020 (S.I. 430 of 2020). No person may produce, reproduce or transmit\n",
      "in any form or by any means this report or any part thereof without the express permission of\n",
      "the RAIU. This report may be freely used for educational purposes.\n",
      "Where the report has been altered following its original publication, details on the changes will\n",
      "Report structure\n",
      "The report structure is written as closely as possible to the structure set out in the “Commission\n",
      "Implementation Regulation (EU) 2020/5\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text by removing headers, footers, and empty lines.\n",
    "    \"\"\"\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Remove page numbers (e.g., \"Page 12\" or \"Railway Accident Investigation Unit  |  2023 Report\")\n",
    "        if re.match(r'^(Page \\d+|Broken Rail near Emly, County Tipperary, 22nd February 2023|Railway Accident Investigation Unit)$', line):\n",
    "            continue\n",
    "\n",
    "        # Remove overly short lines (likely just noise)\n",
    "        if len(line) < 10:\n",
    "            continue\n",
    "\n",
    "        cleaned_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "# Apply cleaning\n",
    "final_cleaned_text = clean_text(cleaned_text)\n",
    "print(final_cleaned_text[:1000])  # Preview cleaned text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Chunk Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 50\n",
      "Sample Chunk: Railway Accident\n",
      "Investigation Unit\n",
      "INVESTIGATION REPORT\n",
      "Broken Rail near Emly,\n",
      "County Tipperary, 22nd February 2023\n",
      "RAIU Investigation Report No: 2024-R002\n",
      "Published: 22nd March 2024\n",
      "Report Description\n",
      "Report publication\n",
      "This report is published by the Railway Accident Investigation Unit (RAIU). The copyright in\n",
      "the enclosed report remains with the RAIU by virtue of in Regulation 9 (7) of European Union\n",
      "(EU) (Railway Safety) (Reporting and Investigation of Serious Accidents, Accidents and\n",
      "Incidents) Regulations 2020 (S.I. 430 of 2020). No person may produce, reproduce or transmit\n",
      "in any form or by any means this report or any part thereof without the express permission of\n",
      "the RAIU. This report may be freely used for educational purposes.\n",
      "Where the report has been altered following its original publication, details on the changes will\n",
      "Report structure\n",
      "The report structure is written as closely as possible to the structure set out in the “Commission\n",
      "Implementation Regulation (EU) 2020/572 of 24 April 2020 on the reporting structure to be\n",
      "followed for railway accident and incident investigation reports” having regard to “Directive\n",
      "(EU) 2016/798 of the European Parliament and of the Council of 11 May 2016 on railway\n",
      "Reader guide\n",
      "All dimensions and speeds in this report are given using the International System of Units (SI\n",
      "Units). Where the normal railway practice, in some railway organisations, is to use imperial\n",
      "dimensions; imperial dimensions are used, and the SI Unit is also given.\n",
      "All abbreviations and technical terms (which appear in italics the first time they appear in the\n",
      "report) are explained in the glossary.\n",
      "Descriptions and figures may be simplified in order to illustrate concepts to non-technical\n",
      "Further information\n",
      "For further information, or to contact the RAIU, please see details below:\n",
      "RAIU email: info@raiu.ie\n",
      "2nd Floor, 2 Leeson Lane website: www.raiu.ie\n",
      "Dublin 2, Ireland. telephone: + 353 1 604 1050\n",
      "Railway Accident Investigation Unit i\n"
     ]
    }
   ],
   "source": [
    "def split_text_into_chunks(text, chunk_size=2000, chunk_overlap=300):\n",
    "    \"\"\"\n",
    "    Splits text into smaller overlapping chunks using LangChain's text splitter.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, \n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "# Split the extracted text\n",
    "text_chunks = split_text_into_chunks(final_cleaned_text)\n",
    "\n",
    "# Print the number of chunks and a sample chunk\n",
    "print(f\"Total Chunks: {len(text_chunks)}\")\n",
    "print(f\"Sample Chunk: {text_chunks[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant Chunk Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword-based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 relevant chunks.\n",
      "Sample Chunk:\n",
      " conditions may have led to a serious accident.\n",
      "The RAIU may also carry out trend investigations where the occurrence is part of a group of\n",
      "related occurrences that may or may not have warranted an investigation as individual\n",
      "occurrences, but the apparent trend warrants investigation.\n",
      "The RAIU investigation shall analyse the established facts and findings (i.e. performance of\n",
      "operators, rolling stock and/or technical installations) which caused the occurrence. The\n",
      "analyses shall then lead to the identification of the safety critical factors that caused or\n",
      "otherwise contributed to the occurrence, including facts identified as precursors. An accident\n",
      "or incident may be caused by causal, contributing and systemic factors which are equally\n",
      "important and should be consider during the RAIU investigation. From this, the RAIU may\n",
      "make safety recommendations in order to prevent accidents and incidents in the future and\n",
      "improve railway safety.\n",
      "It is not the purpose of an RAIU investigation to attribute blame or liability.\n",
      "Railway Accident Investigation Unit ii\n",
      "1 On Tuesday 21st February 2023 a T3 Possession was organised on the Up and Down\n",
      "lines of the Dublin to Cork mainline to allow for a track section, near Emly Level Crossing\n",
      "(LC), to undergo track maintenance.\n",
      "2 As part of the track maintenance, stressing and welding of the rails had to be undertaken\n",
      "in preparation for ballast cleaning.\n",
      "3 The stressing of the rails was being carried out on the Up line, which involved cutting both\n",
      "rails which was marked by a Iarnród Éireann Infrastructure Manager (IÉ-IM) staff member,\n",
      "the Person in Charge of Stressing (this member of IÉ-IM staff was also the Track Delivery\n",
      "Unit Engineer (TDU Engineer) who supervised the works).\n",
      "4 A welding contractor was engaged to carry out the welding at the site location (110 miles\n",
      "355 yards), with a team comprising of a lead and second welder (the Welders) and a Weld\n"
     ]
    }
   ],
   "source": [
    "def find_relevant_chunks(chunks, keyword):\n",
    "    \"\"\"\n",
    "    Returns chunks that contain a specific keyword.\n",
    "    \"\"\"\n",
    "    relevant_chunks = [chunk for chunk in chunks if keyword.lower() in chunk.lower()]\n",
    "    return relevant_chunks\n",
    "\n",
    "# Example: Find chunks mentioning \"location\"\n",
    "location_chunks = find_relevant_chunks(text_chunks, \"location\")\n",
    "\n",
    "print(f\"Found {len(location_chunks)} relevant chunks.\")\n",
    "print(\"Sample Chunk:\\n\", location_chunks[0] if location_chunks else \"No relevant chunks found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector-based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 50 chunks in FAISS.\n"
     ]
    }
   ],
   "source": [
    "# Convert text chunks into FAISS vector database\n",
    "vectorstore = FAISS.from_texts(text_chunks, embeddings)\n",
    "\n",
    "print(f\"Stored {len(text_chunks)} chunks in FAISS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Find the most relevant chunk for a question\n",
    "query_vector = \"Train wagon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Relevant Chunks Combined:\n",
      " February 2023 when the first Cork to Dublin passenger service resumed on the Up line.\n",
      "Railway Accident Investigation Unit 12\n",
      "Rolling Stock\n",
      "52 Twenty-four passenger trains travelled over the welded section of rail, on the Up line, from\n",
      "the 21st February until the time of the weld breaking on the 22nd February 2023; these\n",
      "trains served Cork to Dublin and Tralee to Dublin. The trains involved were MkIV and\n",
      "22000 InterCity Rail car (ICR).\n",
      "53 The MkIV push/pull trains consist of a 201 Class locomotive, a catering vehicle, one 1st\n",
      "class carriage, five standard class carriages and a generator car (see Figure 2). The\n",
      "maximum service speed of the train formation is 100 mph (160 km/h).\n",
      "Figure 2 – MkIV 201 Class Locomotive\n",
      "54 The ICR 22000 series DMU (Rotem) consists of three car and four car sets (see Figure 3).\n",
      "The maximum service speed of the train formation is 100 mph (160 km/h).\n",
      "Figure 3 – 22000 InterCity Rail Cars\n",
      "Railway Accident Investigation Unit 13\n",
      "Signalling & communications\n",
      "55 The line is operated under the rules and regulations for train signalling by Track Circuit\n",
      "Block (TCB) system and is fitted with colour light signals throughout. The Signalman is\n",
      "located at CTC at Connolly Station Dublin.\n",
      "56 The means of communications between the train drivers and the Signalman on route is\n",
      "through train radio.\n",
      "57 The infrastructure and all passenger trains using it are also equipped with the Continuous\n",
      "Automatic Warning System (CAWS).\n",
      "Operations\n",
      "58 Trains travelling towards Dublin are travelling on the Up Line. Trains traveling towards\n",
      "Cork are travelling on the Down Line.\n",
      "59 The maximum line speed, on both lines is 100 mph (160 km/h) subject to permanent and\n",
      "temporary speed restrictions.\n",
      "60 In terms of the passengers services relevant to the incident:\n",
      "• Train A205 – 07:00 hrs passenger service from Cork to Dublin passed over the rail,\n",
      "likely causing the rail to break, and continued on its journey unaffected;\n",
      "• Train A303 – 07:05 hrs passenger service from Tralee to Dublin;\n",
      "60 In terms of the passengers services relevant to the incident:\n",
      "• Train A205 – 07:00 hrs passenger service from Cork to Dublin passed over the rail,\n",
      "likely causing the rail to break, and continued on its journey unaffected;\n",
      "• Train A303 – 07:05 hrs passenger service from Tralee to Dublin;\n",
      "• Train A209 – 09:25 hrs passenger service from Cork to Dublin.\n",
      "Railway Accident Investigation Unit 14\n",
      "Infrastructure (Track & Rails)\n",
      "General description of the track\n",
      "61 The incident occurred on the Dublin to Cork route, on a section of the Up line between\n",
      "Charleville and Limerick Junction. At the location of the incident the railway is a double\n",
      "track formation. The track is flat bottom, continuously welded rails (CWR) mounted on\n",
      "concrete sleepers, set in ballast.\n",
      "General description of rail\n",
      "62 The rails used on this track are 54kg/m E1 profile rail from Arcelor Mittal (see\n",
      "Figure 4) manufactured in their Gijon plan in Spain (formally Ensidesa). The rail product is\n",
      "marked “Ensidesa” and purchased through an ongoing contract in place since 2018. The\n",
      "rail is supplied in 36 m lengths and shipped to Waterford Port by the company where it is\n",
      "handed over to IÉ-IM.\n",
      "Figure 4 – Rail profile 54 kg E1\n",
      "Railway Accident Investigation Unit 15\n",
      "Stressing, Welding & Testing of Rails\n",
      "General description\n",
      "63 This section of the report outlines the stressing, welding and ultrasonic testing of rails and\n",
      "identifies their associated technical standards; it is meant to be an overview of actions to\n",
      "be taken on-site during the welding process. However, the focus of this investigation is in\n",
      "relation to the stressing of the rails during the welding process and associated equipment.\n",
      "Methodology\n",
      "64 Part of the renewal and repairs to tracks involves the stressing of the rails. IÉ-IM carry out\n",
      "the Stressing of Rail as set out in CCE-TMS-323, Technical Standard for Stressing of Rail.\n",
      "65 The Person in Charge of Stressing ensures that the relevant equipment is on site and the\n",
      "(Ultrasonic)\n",
      "Internal Union of Railways (2002), UIC 712R Catalogue of Rail Defects, 4th edition, February\n",
      "Serco Rail Technical Services (2023), Serco Rail Technical Services Report- Investigation of\n",
      "Broken Thermit Weld 15th March 2023.\n",
      "Railway Accident Investigation Unit 48\n"
     ]
    }
   ],
   "source": [
    "def find_most_relevant_chunks(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Finds the most relevant text chunks using FAISS similarity search.\n",
    "    \"\"\"\n",
    "    retrieved_chunks = vectorstore.similarity_search(query, k=top_k)\n",
    "    return [chunk.page_content for chunk in retrieved_chunks]\n",
    "\n",
    "top_chunks = find_most_relevant_chunks(query_vector, top_k=3)\n",
    "\n",
    "relevant_text = \"\\n\".join(top_chunks)\n",
    "\n",
    "print(f\"Most Relevant Chunks Combined:\\n {relevant_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Most Relevant Chunk:\n",
      " February 2023 when the first Cork to Dublin passenger service resumed on the Up line.\n",
      "Railway Accident Investigation Unit 12\n",
      "Rolling Stock\n",
      "52 Twenty-four passenger trains travelled over the welded section of rail, on the Up line, from\n",
      "the 21st February until the time of the weld breaking on the 22nd February 2023; these\n",
      "trains served Cork to Dublin and Tralee to Dublin. The trains involved were MkIV and\n",
      "22000 InterCity Rail car (ICR).\n",
      "53 The MkIV push/pull trains consist of a 201 Class locomotive, a catering vehicle, one 1st\n",
      "class carriage, five standard class carriages and a generator car (see Figure 2). The\n",
      "maximum service speed of the train formation is 100 mph (160 km/h).\n",
      "Figure 2 – MkIV 201 Class Locomotive\n",
      "54 The ICR 22000 series DMU (Rotem) consists of three car and four car sets (see Figure 3).\n",
      "The maximum service speed of the train formation is 100 mph (160 km/h).\n",
      "Figure 3 – 22000 InterCity Rail Cars\n",
      "Railway Accident Investigation Unit 13\n",
      "Signalling & communications\n",
      "55 The line is operated under the rules and regulations for train signalling by Track Circuit\n",
      "Block (TCB) system and is fitted with colour light signals throughout. The Signalman is\n",
      "located at CTC at Connolly Station Dublin.\n",
      "56 The means of communications between the train drivers and the Signalman on route is\n",
      "through train radio.\n",
      "57 The infrastructure and all passenger trains using it are also equipped with the Continuous\n",
      "Automatic Warning System (CAWS).\n",
      "Operations\n",
      "58 Trains travelling towards Dublin are travelling on the Up Line. Trains traveling towards\n",
      "Cork are travelling on the Down Line.\n",
      "59 The maximum line speed, on both lines is 100 mph (160 km/h) subject to permanent and\n",
      "temporary speed restrictions.\n",
      "60 In terms of the passengers services relevant to the incident:\n",
      "• Train A205 – 07:00 hrs passenger service from Cork to Dublin passed over the rail,\n",
      "likely causing the rail to break, and continued on its journey unaffected;\n",
      "• Train A303 – 07:05 hrs passenger service from Tralee to Dublin;\n"
     ]
    }
   ],
   "source": [
    "def keyword_filter(chunks, keyword):\n",
    "    \"\"\"\n",
    "    Filters chunks that contain a specific keyword.\n",
    "    \"\"\"\n",
    "    return [chunk for chunk in chunks if keyword.lower() in chunk.lower()]\n",
    "\n",
    "# First, get the top vector-based matches\n",
    "top_chunks = find_most_relevant_chunks(query_vector, top_k=5)\n",
    "\n",
    "# Then, filter out only those mentioning \"location\" or similar words\n",
    "filtered_chunks = keyword_filter(top_chunks, query_vector)\n",
    "\n",
    "# If no good keyword matches, just use the first vector match\n",
    "final_chunk = filtered_chunks[0] if filtered_chunks else top_chunks[0]\n",
    "\n",
    "print(f\"Filtered Most Relevant Chunk:\\n {final_chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text, model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Counts the number of tokens in a given text for a specified OpenAI model.\n",
    "    \"\"\"\n",
    "    encoder = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoder.encode(text)\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(text):\n",
    "    \"\"\"\n",
    "    Constructs the entity extraction prompt.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "    Extract key entities from the following accident report.\n",
    "\n",
    "    Provide the output in valid JSON format with categories:\n",
    "    - date\n",
    "    - location\n",
    "    - regulatory_body\n",
    "    Ensure that the response is only valid JSON and contains no other text or formatting. Here's an example for you to follow:\n",
    "    {{\n",
    "        \"date\": \"2023-02-22\",\n",
    "        \"location\": \"Emly, County Tipperary\",\n",
    "        \"regulatory_body\": \"Railway Accident Investigation Unit\"\n",
    "    }}\n",
    "    If you cannot extract anything, please provide an empty JSON object.\n",
    "\n",
    "    Here is the text to analyze: {text}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(prompt, temperature=0.3):\n",
    "    \"\"\"\n",
    "    Calls the GPT model with the structured prompt and returns the raw response.\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in analyzing railway accident reports. Return output in JSON format only.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    response_text = completion.choices[0].message.content.strip()\n",
    "    \n",
    "    # Remove markdown JSON formatting if present\n",
    "    response_text = re.sub(r'^```json\\n?|```$', '', response_text).strip()\n",
    "    \n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text, token_limit=1000):\n",
    "    \"\"\"\n",
    "    Extracts key entities from an accident report using GPT.\n",
    "    - First, counts tokens and allows user decision.\n",
    "    - If within limit, runs GPT and handles errors.\n",
    "    \"\"\"\n",
    "    prompt = build_prompt(text)\n",
    "    token_count = count_tokens(prompt)\n",
    "\n",
    "    print(f\"🔹 Token Count for Prompt: {token_count} (Limit: {token_limit})\")\n",
    "\n",
    "    # Allow user to decide if they want to proceed\n",
    "    if token_count > token_limit:\n",
    "        print(\"Token count is too high! Please reduce the chunk size or refine the prompt.\")\n",
    "        return None  # Stops execution here\n",
    "\n",
    "    # Confirm before making the API call\n",
    "    proceed = input(\"Do you want to proceed with extraction? (yes/no): \").strip().lower()\n",
    "    if proceed != \"yes\":\n",
    "        print(\"Extraction aborted by user.\")\n",
    "        return None  # Stops execution\n",
    "\n",
    "    print(\"Sending request to GPT...\")\n",
    "\n",
    "    response_text = call_gpt(prompt)\n",
    "\n",
    "    try:\n",
    "        return json.loads(response_text)  # Ensure valid JSON\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error parsing JSON:\", str(e))\n",
    "        print(\"Storing raw response for review...\")\n",
    "\n",
    "        # Save the faulty response for debugging\n",
    "        with open(\"failed_gpt_responses.json\", \"a\") as file:\n",
    "            json.dump({\"input_text\": text[:1000], \"raw_output\": response_text}, file, indent=4)\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "        return {}  # Return empty dictionary in case of failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Token Count for Prompt: 584 (Limit: 1000)\n",
      "⏳ Sending request to GPT...\n",
      "Extracted Entities: {'date': '2023-02-22', 'location': 'Cork to Dublin', 'regulatory_body': 'Railway Accident Investigation Unit'}\n"
     ]
    }
   ],
   "source": [
    "entities = extract_entities(final_chunk)\n",
    "\n",
    "print(\"Extracted Entities:\", entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    \"\"\"Extract key entities using GPT-4o-mini.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Extract key entities from the following accident report:\n",
    "    {text}\n",
    "    \n",
    "    Provide the output in valid JSON format with categories:\n",
    "    - date\n",
    "    - location\n",
    "    - regulatory_body\n",
    "    Ensure that the response is only valid JSON and contains no other text or formatting.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in analyzing rail accident reports. Return output in JSON format only.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        response_text = completion.choices[0].message.content.strip()\n",
    "        \n",
    "        # Remove markdown JSON formatting if present\n",
    "        response_text = re.sub(r'^```json\\n?|```$', '', response_text).strip()\n",
    "        \n",
    "        return json.loads(response_text)  # Ensure valid JSON\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error parsing JSON from OpenAI response:\", str(e))\n",
    "        print(\"Raw response:\", response_text)\n",
    "        return {}  # Return empty dictionary in case of failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Entities: {\n",
      "    \"date\": \"22nd February 2023\",\n",
      "    \"location\": \"Emly, County Tipperary, Ireland\",\n",
      "    \"regulatory_body\": \"Railway Accident Investigation Unit (RAIU)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test GPT-4o-mini entity extraction\n",
    "entity_json = extract_entities(pdf_text)\n",
    "print(\"Extracted Entities:\", json.dumps(entity_json, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"date\": \"22nd February 2023\", \"location\": \"Emly, County Tipperary, Ireland\", \"regulatory_body\": \"Railway Accident Investigation Unit (RAIU)\"}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(entity_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in Neo4j\n",
    "def store_in_neo4j(json_data):\n",
    "    \"\"\"Store extracted data in Neo4j.\"\"\"\n",
    "    if not json_data:\n",
    "        print(\"No valid entities to store in Neo4j.\")\n",
    "        return\n",
    "    \n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        for category, item in json_data.items():  # Iterate over key-value pairs\n",
    "            if isinstance(item, list):  # If it's a list, iterate over items\n",
    "                for value in item:\n",
    "                    session.run(\"\"\"\n",
    "                        MERGE (n:Entity {name: $name, category: $category})\n",
    "                    \"\"\", name=value, category=category)\n",
    "            else:  # If it's a single string, store it directly\n",
    "                session.run(\"\"\"\n",
    "                    MERGE (n:Entity {name: $name, category: $category})\n",
    "                \"\"\", name=item, category=category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in Neo4j with Relationships\n",
    "def store_in_neo4j(json_data):\n",
    "    \"\"\"Store extracted data in Neo4j and create relationships.\"\"\"\n",
    "    if not json_data:\n",
    "        print(\"No valid entities to store in Neo4j.\")\n",
    "        return\n",
    "    \n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        # Create nodes\n",
    "        session.run(\"\"\"\n",
    "            MERGE (d:Date {name: $date})\n",
    "        \"\"\", date=json_data.get(\"date\", \"Unknown\"))\n",
    "        \n",
    "        session.run(\"\"\"\n",
    "            MERGE (l:Location {name: $location})\n",
    "        \"\"\", location=json_data.get(\"location\", \"Unknown\"))\n",
    "        \n",
    "        session.run(\"\"\"\n",
    "            MERGE (r:RegulatoryBody {name: $regulatory_body})\n",
    "        \"\"\", regulatory_body=json_data.get(\"regulatory_body\", \"Unknown\"))\n",
    "        \n",
    "        # Create relationships\n",
    "        session.run(\"\"\"\n",
    "            MATCH (d:Date {name: $date}), (l:Location {name: $location})\n",
    "            MERGE (d)-[:OCCURRED_AT]->(l)\n",
    "        \"\"\", date=json_data.get(\"date\", \"Unknown\"), location=json_data.get(\"location\", \"Unknown\"))\n",
    "        \n",
    "        session.run(\"\"\"\n",
    "            MATCH (l:Location {name: $location}), (r:RegulatoryBody {name: $regulatory_body})\n",
    "            MERGE (l)-[:REGULATED_BY]->(r)\n",
    "        \"\"\", location=json_data.get(\"location\", \"Unknown\"), regulatory_body=json_data.get(\"regulatory_body\", \"Unknown\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored in Neo4j successfully.\n"
     ]
    }
   ],
   "source": [
    "# Store extracted entities into Neo4j\n",
    "try:\n",
    "    db_result = store_in_neo4j(entity_json)\n",
    "    print(\"Data stored in Neo4j successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to store data in Neo4j:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Neo4j connection\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

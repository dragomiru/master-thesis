{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General \n",
    "import os\n",
    "\n",
    "# PDFs\n",
    "import pdfplumber\n",
    "import json\n",
    "import regex as reg\n",
    "\n",
    "# LLMs\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "import faiss\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.graphs.graph_document import (\n",
    "    Node as BaseNode,\n",
    "    Relationship as BaseRelationship,\n",
    "    GraphDocument,\n",
    ")\n",
    "from langchain.schema import Document\n",
    "from pydantic import Field, BaseModel\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# Neo4j\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import AuthError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Railway Accident\n",
      "Investigation Unit\n",
      "Ireland\n",
      "INVESTIGATION REPORT\n",
      "Collision between a car and a train at\n",
      "Level Crossing XM190, Mayo, 9th September 2023\n",
      "RAIU Investigation Report No: 2024-R003\n",
      "Published: 12/12/2024\n",
      "Collision between a car and a train at Level Crossing XM190, Mayo, 9th September 2023\n",
      "Report Description\n",
      "Report publication\n",
      "This report is published by the Railway Accident Investigation Unit (RAIU). The copyright in\n",
      "the enclosed report remains with the RAIU by virtue of Regulation 9 (7\n"
     ]
    }
   ],
   "source": [
    "# Extract the text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a given PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Test PDF extraction\n",
    "pdf_text = extract_text_from_pdf(\"raiu_example_collision.pdf\")\n",
    "print(pdf_text[:500])  # Print first 500 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processed Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1:\n",
      "Railway Accident\n",
      "Investigation Unit\n",
      "Ireland\n",
      "INVESTIGATION REPORT\n",
      "Collision between a car and a train at\n",
      "Level Crossing XM190, Mayo, 9th September 2023\n",
      "RAIU Investigation Report No: 2024-R003\n",
      "Published: 12/12/2024\n",
      "----------------------------------------\n",
      "Page 2:\n",
      "Collision between a car and a train at Level Crossing XM190, Mayo, 9th September 2023\n",
      "Report Description\n",
      "Report publication\n",
      "This report is published by the Railway Accident Investigation Unit (RAIU). The copyright in\n",
      "the enclosed report remains with the RAIU by virtue of Regulation 9 (7) of European Union\n",
      "(EU) (Railway Safety) (Reporting and Investigation of Serious Accidents, Accidents and\n",
      "Incidents) Regulations 2020 (S.I. 430 of 2020). No person may produce, reproduce or transmit\n",
      "in any form o\n",
      "----------------------------------------\n",
      "Page 3:\n",
      "Collision between a car and a train at Level Crossing XM190, Mayo, 9th September 2023\n",
      "Preface\n",
      "The RAIU is an independent investigation unit within the Department of Transport which\n",
      "conducts investigations into accidents and incidents on the national railway network including\n",
      "the Dublin Area Rapid Transit (DART) network, the Luas light rail system, heritage and\n",
      "industrial railways in Ireland. Investigations are carried out in accordance with the Railway\n",
      "Safety Directive (EU) 2016/798 enshrined in\n",
      "----------------------------------------\n",
      "Page 4:\n",
      "Collision between a car and a train at Level Crossing XM190, Mayo, 9th September 2023\n",
      "Summary\n",
      "At approximately 15:15 hours (hrs) on Saturday the 9th September 2023, the Iarnród Éireann\n",
      "(IÉ) 12:45 hrs Heuston to Westport passenger service (Train A804) was approaching\n",
      "Prendergast’s Level Crossing (LC), asset number XM190 (to be referred to as LC XM190),\n",
      "located between Ballyhaunis and Claremorris (County Mayo), at a speed of 70 miles per hour\n",
      "(mph) (110 kilometres per hour (km/h)). The train drive\n",
      "----------------------------------------\n",
      "Page 5:\n",
      "Collision between a car and a train at Level Crossing XM190, Mayo, 9th September 2023\n",
      "The car sustained substantial damage on impact and was propelled approximately 31 metres\n",
      "(m) into an adjacent field landing on the passenger side.\n",
      "The front of Train A804 came to a stop 310 m past the centre of LC XM190.\n",
      "Driver A804 contacted the Mayo Line Signalman requesting emergency service and followed\n",
      "all other post-accident procedures correctly.\n",
      "The two occupants of the car sustained injuries (the passen\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF while allowing for pre-processing.\n",
    "    \"\"\"\n",
    "    text = []\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text.append(page_text)\n",
    "    \n",
    "    return text  # Returns a list where each item is a page's text\n",
    "\n",
    "# Extract pages as a list\n",
    "pdf_pages = extract_text_from_pdf(\"raiu_example_collision.pdf\")\n",
    "\n",
    "# Print the first few pages to inspect where the TOC might be\n",
    "for i, page in enumerate(pdf_pages[:5]):  # Check first 5 pages\n",
    "    print(f\"Page {i+1}:\\n{page[:500]}\\n{'-'*40}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Railway Accident\n",
      "Investigation Unit\n",
      "Ireland\n",
      "INVESTIGATION REPORT\n",
      "Collision between a car and a train at\n",
      "Level Crossing XM190, Mayo, 9th September 2023\n",
      "RAIU Investigation Report No: 2024-R003\n",
      "Published: 12/12/2024\n",
      "Collision between a car and a train at Level Crossing XM190, Mayo, 9th September 2023\n",
      "Report Description\n",
      "Report publication\n",
      "This report is published by the Railway Accident Investigation Unit (RAIU). The copyright in\n",
      "the enclosed report remains with the RAIU by virtue of Regulation 9 (7) of European Union\n",
      "(EU) (Railway Safety) (Reporting and Investigation of Serious Accidents, Accidents and\n",
      "Incidents) Regulations 2020 (S.I. 430 of 2020). No person may produce, reproduce or transmit\n",
      "in any form or by any means this report or any part thereof without the express permission of\n",
      "the RAIU. This report may be freely used for educational purposes.\n",
      "Where the report has been altered following its original publication, details on the changes will\n",
      "be given.\n",
      "Report structure\n",
      "The report structure is written as close as possible to the structure set out in the “Commission\n",
      "Implementation Regulation (EU) 2020/572 of 24 April 2020 on the reporting structure to be\n",
      "followed for railway accident and incident investigation reports” having regard to “Directive\n",
      "(EU) 2016/798 of the European Parliament and of the Council of 11 May 2016 on railway\n",
      "safety”.\n",
      "Reader guide\n",
      "All dimensions and speeds in this report are given using the International System of Units (SI\n",
      "Units). Where the normal railway practice, in some railway organisations, is to use imperial\n",
      "dimensions; imperial dimensions are used, and the SI Unit is also given.\n",
      "All abbreviations and technical terms (which appear in italics the first time they appear in the\n",
      "report) are explained in the glossary.\n",
      "Descriptions and figures may be simplified in order to illustrate concepts to non-technical\n",
      "readers.\n",
      "Further information\n",
      "For further information, or to contact the RAIU, please see details below:\n",
      "RAIU email: info@raiu.ie\n",
      "2nd Floor, 2 Leeson Lane website: www.raiu.ie\n",
      "Dublin 2, Ireland. telephone: + 353 1 604 1050\n",
      "Railway Accident Investigation Unit i\n",
      "Collision between a car and a train at Level Crossing XM190, Mayo, 9th September 2023\n",
      "Preface\n",
      "The RAIU is an independent investigation unit within the Department of Transport which\n",
      "conducts investigations into accidents and incidents on the national railway network including\n",
      "the Dublin Area Rapid Transit (DART) network, the Luas light rail system, heritage and\n",
      "industrial railways in Ireland. Investigations are carried out in accordance with the Railway\n",
      "Safety Directive (EU) 2016/798 enshrined in the European Union (Railway Safety) (Reporting\n",
      "and Investigation of Serious Accidents, Accidents and Incidents) Regulations 2020; and,\n",
      "where relevant, by the application of the Railway Safety (Reporting and Investigation of\n",
      "Serious Accidents, Accidents and Incidents Involving Certain Railways) Act 2020.\n",
      "The RAIU investigate all serious accidents. A serious accident means any train collision or\n",
      "derailment of trains, resulting in the death of at least one person or serious injuries to five or\n",
      "more persons or extensive damage to rolling stock, the infrastructure or the environment, and\n",
      "any other similar accident with an obvious impact on railway or tramline safety regulation or\n",
      "the management of safety. During an investigation, if the RAIU make some early findings on\n",
      "safety issues that require immediate action, the RAIU will issue an Urgent Safety Advice\n",
      "Notice outlining the associated safety recommendation(s); other issues may require a Safety\n",
      "Advice Notice.\n",
      "The RAIU may investigate and report on accidents and incidents which under slightly different\n",
      "conditions may have led to a serious accident.\n",
      "The RAIU may also carry out trend investigations where the occurrence is part of a group of\n",
      "related occurrences that may or may not have warranted an investigation as individual\n",
      "occurrences, but the apparent trend warrants investigation.\n",
      "The RAIU investigation shall analyse the established facts and findings (i.e. performance of\n",
      "operators, rolling stock and/or technical installations) which caused the occurrence. The\n",
      "analyses shall then lead to the identification of the safety critical factors that caused or\n",
      "otherwise contributed to the occurrence, including facts identified as precursors. An accident\n",
      "or incident may be caused by causal, contributing and systemic factors which are equally\n",
      "important and should be consider during the RAIU investigation. From this, the RAIU may\n",
      "make safety recommendations in order to prevent accidents and incidents in the future and\n",
      "improve railway safety.\n",
      "It is not the purpose of an RAIU investigation to attribute blame or liability.\n",
      "Railway Accident Investigation Unit ii\n",
      "Collision between a car and a train at Level Crossing XM190, Mayo, 9th September 2023\n",
      "Summary\n",
      "At approximately 15:15 hours (hrs) on Saturday the 9th September 2023, the Iarnród Éireann\n",
      "(IÉ) 12:45 hrs Heuston to Westport passenger service (Train A804) was approaching\n",
      "Prendergast’s Level Crossing (LC), asset number XM190 (to be referred to as LC XM190),\n",
      "located between Ballyhaunis and Claremorris (County Mayo), at a speed of 70 miles per hour\n",
      "(mph) (110 kilometres per hour (km/h)). The train driver (Driver A804) sounded the horn at the\n",
      "whistle board associated with LC XM190 on their approach.\n",
      "LC XM190 is an Occupational Public (OP) user worked unattended level crossing (UWLC)\n",
      "meaning it is guarded by metal gates across a public road; whereby a member of the public,\n",
      "the “user”, will have to open and shut the gates to cross the railway and continue on the road.\n",
      "At the same time as Train A804 was approaching LC XM190 a car was also approaching LC\n",
      "XM190 from the up side (right hand side from the perspective of Driver A804). The car was\n",
      "travelling on a rural local road L65516 which links national road, N60, with another local road,\n",
      "L5551, and onto the N17. The speed limit for the local road is 80 km/h. The driver of the car\n",
      "(Car Driver) had taken a wrong turn at Claremorris and their satellite navigation system had\n",
      "diverted them onto these local roads which routed them over LC XM190 to continue on their\n",
      "journey.\n",
      "On the approach to LC XM190 there are three “Level Crossing with No Flashing Red Signal\n",
      "(with Barriers or Gates)” advance warning signs (Sign W121) located at 100 metres (m), 200\n",
      "m and 300 m in advance of LC XM190. In addition, there is a “Warning Railway Crossing\n",
      "Ahead Stop before you Cross the Railway” sign, a mandatory Stop Sign (Sign RUS 027), and\n",
      "a “Warning Trains” sign mounted on poles at LC XM190.\n",
      "The gates at LC XM190 were left open to road traffic by a previous unknown user of LC\n",
      "XM190.\n",
      "When Driver A804 saw the car approaching LC XM190 they sounded the train horn again.\n",
      "Driver A804 could see that the car was travelling “a bit fast” and made a full service brake\n",
      "application and continued to sound the horn. On realising the car was not going to stop, Driver\n",
      "A804 made an emergency brake application.\n",
      "As Train A804 slowed, Driver A804 saw that the car was also slowing while arriving onto LC\n",
      "XM190, with the car coming to a “standstill” on the railway line.\n",
      "There was insufficient time to bring Train A804 to a stop before reaching LC XM190 and Train\n",
      "A804 collided with the car (at the time of the collision the coupler was in the extended position\n",
      "as a result of issues with retracting couplers on the Intercity Railcar (ICR Fleet)).\n",
      "Railway Accident Investigation Unit iii\n",
      "Collision between a car and a train at Level Crossing XM190, Mayo, 9th September 2023\n",
      "The car sustained substantial damage on impact and was propelled approximately 31 metres\n",
      "(m) into an adjacent field landing on the passenger side.\n",
      "The front of Train A804 came to a stop 310 m past the centre of LC XM190.\n",
      "Driver A804 contacted the Mayo Line Signalman requesting emergency service and followed\n",
      "all other post-accident procedures correctly.\n",
      "The two occupants of the car sustained injuries (the passenger sustained life-changing\n",
      "injuries) and were treated at the scene before been airlifted to hospital for treatment.\n",
      "The RAIU have identified the following causal factors (CaF) relating to the collision of Train\n",
      "A804 with a car at LC XM190, as follows:\n",
      "• CaF-01 – The gates at LC XM190 were left open by a previous user;\n",
      "• CaF-02 – The Car Driver was unfamiliar with Occupational Public (OP) Type level\n",
      "crossings and as a result the Car Driver did not:\n",
      "• React to the three advance warning signs (Sign W 121) on approach to LC XM190 by\n",
      "slowing the car;\n",
      "• Obey the instructions listed in the “Danger Live Railway Crossing” sign at LC XM190;\n",
      "• Stop at the Stop Sign or Stop Line to look for approaching trains as required by Road\n",
      "Safety Authority’s (RSA) Rules of the Road.\n",
      "The following may have been a contributory factor (CoF) to the damage and injuries sustained\n",
      "to the car occupants and car:\n",
      "• CoF-01 – The coupler was in the extended position (as a result of issues related to\n",
      "retracting the coupler). Had the coupler been retracted, it may have reduced the rate of\n",
      "rotation of the car from the initial impact and may have reduced the damage sustained by\n",
      "the car and the subsequent injuries to the car occupants. However, it cannot be\n",
      "determined, what damage the car would have sustained had the coupler been retracted\n",
      "(i.e. there could have been worse damage; and in addition, there could have been other\n",
      "unintended unwanted consequences).\n",
      "The RAIU have identified the following likely systemic factor (SF) to the accident:\n",
      "• SF-01 – SF-01 - Sign W 121 does not portray clear meaning that the user is approaching\n",
      "a UWLC, a hazard (i.e. live railway) and does not indicate the severity of not adhering to\n",
      "the warning (i.e. being struck by a train).\n",
      "Railway Accident Investigation Unit iv\n",
      "Collision between a car and a train at Level Crossing XM190, Mayo, 9th September 2023\n",
      "At the time of the accident, a Decision Support System (DSS), which provides information for\n",
      "users on the approach of trains, was present at LC XM\n"
     ]
    }
   ],
   "source": [
    "def extract_text_omit_toc(pdf_path, toc_start=7, toc_end=9):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF while skipping the Table of Contents.\n",
    "    \"\"\"\n",
    "    text = []\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            if toc_start <= i+1 <= toc_end:  # Skip TOC pages\n",
    "                continue\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text.append(page_text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Extract text without TOC\n",
    "filtered_pdf_pages = extract_text_omit_toc(\"raiu_example_collision.pdf\")\n",
    "\n",
    "# Join pages into a single text document\n",
    "cleaned_text = \"\\n\".join(filtered_pdf_pages)\n",
    "print(cleaned_text[:10000])  # Preview the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Railway Accident\n",
      "Investigation Unit\n",
      "Ireland\n",
      "INVESTIGATION REPORT\n",
      "Collision between a car and a train at\n",
      "Level Crossing XM190, Mayo, 9th September 2023\n",
      "RAIU Investigation Report No: 2024-R003\n",
      "Published: 12/12/2024\n",
      "Report Description\n",
      "Report publication\n",
      "This report is published by the Railway Accident Investigation Unit (RAIU). The copyright in\n",
      "the enclosed report remains with the RAIU by virtue of Regulation 9 (7) of European Union\n",
      "(EU) (Railway Safety) (Reporting and Investigation of Serious Accidents, Accidents and\n",
      "Incidents) Regulations 2020 (S.I. 430 of 2020). No person may produce, reproduce or transmit\n",
      "in any form or by any means this report or any part thereof without the express permission of\n",
      "the RAIU. This report may be freely used for educational purposes.\n",
      "Where the report has been altered following its original publication, details on the changes will\n",
      "be given.\n",
      "Report structure\n",
      "The report structure is written as close as possible to the structure set out in the “Commission\n",
      "Imp\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text by removing headers, footers, and empty lines.\n",
    "    \"\"\"\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if re.match(r'^(Page \\d+|Collision between a car and a train at Level Crossing XM190, Mayo, 9th September 2023|Railway Accident Investigation Unit)$', line):\n",
    "            continue\n",
    "\n",
    "        cleaned_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "# Apply cleaning\n",
    "final_cleaned_text = clean_text(cleaned_text)\n",
    "print(final_cleaned_text[:1000])  # Preview cleaned text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Chunk Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 88\n"
     ]
    }
   ],
   "source": [
    "def split_text_into_chunks(text, chunk_size=2000, chunk_overlap=300):\n",
    "    \"\"\"\n",
    "    Splits text into smaller overlapping chunks using LangChain's text splitter.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, \n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "# Split the extracted text\n",
    "text_chunks = split_text_into_chunks(final_cleaned_text)\n",
    "\n",
    "# Print the number of chunks and a sample chunk\n",
    "print(f\"Total Chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant Chunk Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword-based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_relevant_chunks(chunks, keyword):\n",
    "#     \"\"\"\n",
    "#     Returns chunks that contain a specific keyword.\n",
    "#     \"\"\"\n",
    "#     relevant_chunks = [chunk for chunk in chunks if keyword.lower() in chunk.lower()]\n",
    "#     return relevant_chunks\n",
    "\n",
    "# # Example: Find chunks mentioning \"location\"\n",
    "# location_chunks = find_relevant_chunks(text_chunks, \"location\")\n",
    "\n",
    "# print(f\"Found {len(location_chunks)} relevant chunks.\")\n",
    "# print(\"Sample Chunk:\\n\", location_chunks[0] if location_chunks else \"No relevant chunks found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector-based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 88 chunks in FAISS.\n"
     ]
    }
   ],
   "source": [
    "# Convert text chunks into FAISS vector store\n",
    "vectorstore = FAISS.from_texts(text_chunks, embeddings)\n",
    "\n",
    "print(f\"Stored {len(text_chunks)} chunks in FAISS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for entity: date\n",
      "Searching for entity: location\n",
      "Searching for entity: regulatory_body\n",
      "Found 3 unique relevant chunks.\n",
      "Most Relevant Chunks Combined:\n",
      "board to remain in situ, and the horn must still be sounded. When no longer required a\n",
      "whistle board will be removed”.\n",
      "Railway Accident Investigation Unit 77\n",
      "Safety Campaigns\n",
      "266 IÉ-IM continue to promote level crossing safety, when suitable events to promote,\n",
      "arise, examples are as follows:\n",
      "• June 2024 – Nine level crossings were attended in recognition of International Level\n",
      "Crossing Awareness Day (ILCAD). IÉ-IM coordinated this initiative with An Garda\n",
      "Síochána Roads Policing Units and the RSA. All level crossing users were stopped and\n",
      "engaged on the day, distributing safety information leaflets and answering any queries.\n",
      "ILCAD is an annual event in which IÉ-IM will be supporting each year;\n",
      "• June 2024 – IÉ-IM updated all of their UWLC booklets and refreshed the website to\n",
      "highlight these updates;\n",
      "• June 2024 – IÉ-IM targeted professional road hauliers by publishing a level crossing\n",
      "safety and awareness article in the June edition of Fleet Management Magazine. This\n",
      "included a copy of the IÉ-IM Booklet, with 7,300 hard copies distributed and sold during\n",
      "that month;\n",
      "• September 2024 – IÉ participated in the WorldSkills Ireland event at the RDS, where\n",
      "IÉ-IM showcased one of the level crossing safety wrapped vans. This was done in\n",
      "collaboration with IÉ-IM’s Apprentice Training Centre promoting level crossing safety\n",
      "and awareness;\n",
      "• Since September 2024 – With roll out of the DSS system, IÉ-IM have had numerous\n",
      "engagements and briefings including local and media channels informing level crossing\n",
      "users that some level crossing have been fitted with the DSS systems (such as local\n",
      "advertising, see Figure 58);\n",
      "• October 2024 – An IÉ-IM Senior Technical Executives from Track and Structures and\n",
      "the Road Fleet Department supported the annual Road Safety event at Athlone\n",
      "Stadium, organised by Youth Work Ireland Midlands where a presentation was\n",
      "delivered on Level Crossing Safety and Awareness to nearly 1,200 Transition Year\n",
      "SMS Safety Management System\n",
      "TCB Track Circuit Block\n",
      "UWLC User Worked Unattended Level Crossing\n",
      "Railway Accident Investigation Unit 84\n",
      "Glossary of terms\n",
      "Accident An unwanted or unintended sudden event or a specific chain of such\n",
      "events which have harmful consequences. For heavy rail, the EU\n",
      "Agency for Railways divides accidents into the following categories:\n",
      "collisions, derailments, level-crossing accidents, accidents to persons\n",
      "caused by rolling stock in motion, fires and others.\n",
      "Article 20 of Article 20 (1) Member States shall ensure that an investigation is\n",
      "Directive (EU) carried out by the investigating body referred to in Article 22 after any\n",
      "2016/798, serious accident on the Union rail system. The objective of the\n",
      "Obligation to investigation shall be to improve, where possible, railway safety and\n",
      "investigation the prevention of accidents.\n",
      "Article 20 (2) The investigating body referred to in Article 22 may also\n",
      "investigate those accidents and incidents which under slightly different\n",
      "conditions might have led to serious accidents, including technical\n",
      "failures of the structural subsystems or of interoperability constituents\n",
      "of the Union rail system. The investigating body may decide whether\n",
      "or not an investigation of such an accident or incident is to be\n",
      "undertaken. In making its decision it shall take into account:\n",
      "(a) the seriousness of the accident or incident;\n",
      "(b) whether it forms part of a series of accidents or incidents relevant\n",
      "to the system as a whole;\n",
      "(c) its impact on railway safety; and\n",
      "(d) requests from infrastructure managers, railway undertakings, the\n",
      "national safety authority or the Member States.\n",
      "Coupler A device which simultaneously couple two rail vehicles together\n",
      "(Automatic) mechanical, electrically and pneumatically.\n",
      "Causal Factor Any action, omission, event or condition, or a combination thereof that\n",
      "if corrected, eliminated, or avoided would have prevented the\n",
      "occurrence, in all likelihood.\n",
      "the Road Fleet Department supported the annual Road Safety event at Athlone\n",
      "Stadium, organised by Youth Work Ireland Midlands where a presentation was\n",
      "delivered on Level Crossing Safety and Awareness to nearly 1,200 Transition Year\n",
      "students from Roscommon, Westmeath, Offaly and Longford;\n",
      "• As part of the Foynes rail freight line project, the main contractor, is meeting with locals\n",
      "to brief them on the safe use of their level crossings as the line is being restored.\n",
      "Railway Accident Investigation Unit 78\n",
      "Internal investigation\n",
      "267 IÉ-IM Safety conducted their own internal investigation into the accident, publishing\n",
      "“Report of Investigation: Train A804 collision with car at level crossing XM190 9th of\n",
      "September 2023” on the 7th June 2024. This report resulted in two recommendations, the\n",
      "recommendations are addressed to and are as follows:\n",
      "• Recommendation 1 – The Head of Health and Safety IÉ-IM in conjunction with the\n",
      "Head of Health and Safety IÉ-RU to conduct a review of existing technologies to assist\n",
      "with identifying the exact location of trains post occurrence relative to railway access\n",
      "points and assess how this would be available to all signal control locations51;\n",
      "• Recommendation 2 – The Head of Health and Safety IÉ-IM in conjunction with the\n",
      "Head of Health and Safety IÉ-RU to issue a guidance document for occurrences that\n",
      "would not require the full implementation of the Emergency Response Handbook. This\n",
      "should include areas of responsibility both on and off site52.\n",
      "268 A the time of publication of the RAIU report, these recommendations remain open.\n",
      "51 This was as a result of the initial confusion as regards to the exact location and access point.\n",
      "Technologies available to IÉ are IÉ’s Remote Diagnostic System, Nexala (an automated\n",
      "communications process by which train system data are collected from the train and\n",
      "transmitted to receiving equipment for monitoring and analysing and IAMS.\n"
     ]
    }
   ],
   "source": [
    "def find_most_relevant_chunks(entities, top_k=1):\n",
    "    \"\"\"\n",
    "    Finds the most relevant text chunks for each entity of interest\n",
    "    using FAISS similarity search and removes duplicates.\n",
    "    \n",
    "    Args:\n",
    "    - entities (list): List of entity names to query (e.g., [\"date\", \"location\", \"regulatory_body\"])\n",
    "    - top_k (int): Number of chunks to retrieve per entity\n",
    "    \n",
    "    Returns:\n",
    "    - unique_relevant_chunks (list): Deduplicated relevant chunks\n",
    "    \"\"\"\n",
    "    retrieved_chunks = set()  # Use a set to avoid duplicate chunks\n",
    "\n",
    "    for entity in entities:\n",
    "        print(f\"Searching for entity: {entity}\")\n",
    "        query = f\"Information about {entity}.\"\n",
    "        found_chunks = vectorstore.similarity_search(query, k=top_k)\n",
    "\n",
    "        for chunk in found_chunks:\n",
    "            retrieved_chunks.add(chunk.page_content)  # Add chunk if not already present\n",
    "\n",
    "    # Convert set back to a list and join into a single string\n",
    "    unique_relevant_chunks = list(retrieved_chunks)\n",
    "    combined_text = \"\\n\".join(unique_relevant_chunks)\n",
    "\n",
    "    print(f\"Found {len(unique_relevant_chunks)} unique relevant chunks.\")\n",
    "    return combined_text\n",
    "\n",
    "# Define entities of interest\n",
    "entities_of_interest = [\"date\", \"location\", \"regulatory_body\"]\n",
    "\n",
    "# Find & combine relevant chunks\n",
    "relevant_text = find_most_relevant_chunks(entities_of_interest, top_k=1)\n",
    "\n",
    "print(f\"Most Relevant Chunks Combined:\\n{relevant_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the API key and model name\n",
    "MODEL=\"gpt-4o-mini\"\n",
    "\n",
    "# Load OpenAI API Key from requirements file\n",
    "with open(\"gpt-personal-key.txt\", \"r\") as file:\n",
    "    OPENAI_API_KEY = file.read().strip()\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text, model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Counts the number of tokens in a given text for a specified OpenAI model.\n",
    "    \"\"\"\n",
    "    encoder = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoder.encode(text)\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Property(BaseModel):\n",
    "    \"\"\"A single property consisting of key and value.\"\"\"\n",
    "    key: str = Field(..., description=\"Property key\")\n",
    "    value: str = Field(..., description=\"Property value\")\n",
    "\n",
    "class Node(BaseNode):\n",
    "    \"\"\"Represents an entity in the railway accident knowledge graph.\"\"\"\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of node properties\")\n",
    "\n",
    "class Relationship(BaseRelationship):\n",
    "    \"\"\"Represents a relationship between two entities in the graph.\"\"\"\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of relationship properties\"\n",
    "    )\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"A knowledge graph storing railway accident data.\"\"\"\n",
    "    nodes: List[Node] = Field(\n",
    "        ..., description=\"List of nodes in the knowledge graph\")\n",
    "    rels: List[Relationship] = Field(\n",
    "        ..., description=\"List of relationships in the knowledge graph\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(prompt, temperature=1):\n",
    "    \"\"\"\n",
    "    Calls the GPT model with the structured prompt and returns the raw response.\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in analyzing railway accident reports. Return output in JSON format only. Very important: the `source` and `target` nodes in `rels` must be the same entities from the `nodes` list, and not different ones.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    response_text = completion.choices[0].message.content.strip()\n",
    "    \n",
    "    # Remove markdown JSON formatting if present\n",
    "    response_text = re.sub(r'^```json\\n?|```$', '', response_text).strip()\n",
    "    \n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(text):\n",
    "    \"\"\"\n",
    "    Constructs a structured prompt to extract entities and relationships for railway accidents.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "    Analyze the following railway accident report context and extract structured knowledge.\n",
    "\n",
    "    Return a JSON object with:\n",
    "    - `nodes`: A list of entities, specifically {entities_of_interest}.\n",
    "    - `rels`: A list of relationships linking entities.\n",
    "\n",
    "    Example JSON response:\n",
    "    {{\n",
    "        \"nodes\": [\n",
    "            {{\"id\": \"Train Derailment\", \"type\": \"AccidentType\"}},\n",
    "            {{\"id\": \"23-12-2021\", \"type\": \"Date\"}},\n",
    "            {{\"id\": \"Dublin, Ireland\", \"type\": \"Location\"}},\n",
    "            {{\"id\": \"European Rail Agency\", \"type\": \"RegulatoryBody\"}}\n",
    "            \n",
    "        ],\n",
    "        \"rels\": [\n",
    "            {{\"source\": \"Train Derailment\", \"target\": \"Dublin, Ireland\", \"type\": \"occurred_at\"}},\n",
    "            {{\"source\": \"Train Derailment\", \"target\": \"European Rail Agency\", \"type\": \"investigated_by\"}}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    Text:\n",
    "    {text}\n",
    "\n",
    "    JSON:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_knowledge_graph(text, token_limit=4096):\n",
    "    \"\"\"\n",
    "    Extracts structured knowledge graph (entities & relationships) from a railway accident report using GPT.\n",
    "    - First, counts tokens and allows user decision.\n",
    "    - If within limit, runs GPT and handles errors.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Build Structured Graph Extraction Prompt\n",
    "    prompt = build_prompt(text)\n",
    "    \n",
    "    # Step 2: Count Tokens\n",
    "    token_count = count_tokens(prompt)\n",
    "    estimated_cost = token_count * 0.00000015  # Approximate OpenAI pricing\n",
    "\n",
    "    print(f\"Token Count for Prompt: {token_count} (Limit: {token_limit})\")\n",
    "    print(f\"Estimated Cost for {MODEL}: ${estimated_cost:.7f}\")\n",
    "\n",
    "    # Step 3: Check Token Limit\n",
    "    if token_count > token_limit:\n",
    "        print(\"Token count is too high! Please reduce the chunk size or refine the prompt.\")\n",
    "        return None  # Stop execution here\n",
    "\n",
    "    # Step 4: Confirm Execution\n",
    "    proceed = input(\"Do you want to proceed with knowledge graph extraction? (yes/no): \").strip().lower()\n",
    "    if proceed != \"yes\":\n",
    "        print(\"Extraction aborted by user.\")\n",
    "        return None  # Stop execution\n",
    "\n",
    "    print(\"Sending request to GPT...\")\n",
    "\n",
    "    # Step 5: Call GPT for Extraction\n",
    "    response_text = call_gpt(prompt)\n",
    "\n",
    "    # Step 6: Process Response & Handle JSON Errors\n",
    "    try:\n",
    "        extracted_graph = json.loads(response_text)  # Ensure valid JSON\n",
    "        return extracted_graph  # Successfully parsed knowledge graph\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error parsing JSON:\", str(e))\n",
    "        print(\"Storing raw response for review...\")\n",
    "\n",
    "        # Save the faulty response for debugging\n",
    "        with open(\"failed_graph_extractions.json\", \"a\") as file:\n",
    "            json.dump({\"input_text\": text[:1000], \"raw_output\": response_text}, file, indent=4)\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "        return {}  # Return empty dictionary in case of failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count for Prompt: 1442 (Limit: 4096)\n",
      "Estimated Cost for gpt-4o-mini: $0.0002163\n",
      "Sending request to GPT...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nodes': [{'id': '9th of September 2023', 'type': 'Date'},\n",
       "  {'id': 'Level Crossing XM190', 'type': 'Location'},\n",
       "  {'id': 'Railway Accident Investigation Unit', 'type': 'RegulatoryBody'}],\n",
       " 'rels': [{'source': '9th of September 2023',\n",
       "   'target': 'Level Crossing XM190',\n",
       "   'type': 'occurred_at'},\n",
       "  {'source': '9th of September 2023',\n",
       "   'target': 'Railway Accident Investigation Unit',\n",
       "   'type': 'investigated_by'}]}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_json = extract_knowledge_graph(relevant_text)\n",
    "response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def props_to_dict(props) -> dict:\n",
    "    \"\"\"Converts properties to a dictionary for graph storage.\"\"\"\n",
    "    properties = {}\n",
    "    if not props:\n",
    "        return properties\n",
    "    for p in props:\n",
    "        properties[p[\"key\"]] = p[\"value\"]\n",
    "    return properties\n",
    "\n",
    "def map_to_base_node(node: Node) -> BaseNode:\n",
    "    \"\"\"Maps extracted entities to graph nodes.\"\"\"\n",
    "    properties = {\"name\": node.id}\n",
    "    return BaseNode(\n",
    "        id=node.id,\n",
    "        type=node.type.capitalize(),\n",
    "        properties=properties\n",
    "    )\n",
    "\n",
    "def map_to_base_relationship(rel: Relationship) -> BaseRelationship:\n",
    "    \"\"\"Maps extracted relationships to graph edges.\"\"\"\n",
    "    source = map_to_base_node(rel.source)\n",
    "    target = map_to_base_node(rel.target)\n",
    "    properties = props_to_dict(rel.properties) if rel.properties else {}\n",
    "\n",
    "    return BaseRelationship(\n",
    "        source=source, target=target, type=rel.type, properties=properties\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Neo4j successfully.\n"
     ]
    }
   ],
   "source": [
    "# Neo4j Connection Setup\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"password\"\n",
    "NEO4J_DATABASE = \"neo4j\"\n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "try:\n",
    "    # Test the connection\n",
    "    with driver.session() as session:\n",
    "        session.run(\"RETURN 1\")\n",
    "    print(\"Connected to Neo4j successfully.\")\n",
    "except AuthError as e:\n",
    "    print(\"Authentication failed. Check your credentials:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j database cleared successfully.\n"
     ]
    }
   ],
   "source": [
    "def clear_neo4j_database():\n",
    "    \"\"\"Delete all nodes and relationships in the Neo4j database.\"\"\"\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "    print(\"Neo4j database cleared successfully.\")\n",
    "\n",
    "# Run the function to clear the database\n",
    "clear_neo4j_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_graph(response_json, source_text):\n",
    "    \"\"\"\n",
    "    Converts extracted JSON into a graph-compatible format with nodes and relationships.\n",
    "    \"\"\"\n",
    "    if not response_json:\n",
    "        print(\"⚠ No valid data to convert to a graph.\")\n",
    "        return None\n",
    "\n",
    "    # Convert Nodes\n",
    "    graph_nodes = [map_to_base_node(Node(id=node[\"id\"], type=node[\"type\"])) for node in response_json[\"nodes\"]]\n",
    "\n",
    "    # Convert Relationships\n",
    "    graph_rels = []\n",
    "    for rel in response_json[\"rels\"]:\n",
    "        source_node = Node(id=rel[\"source\"], type=\"Unknown\")  # Temporary, type should be resolved\n",
    "        target_node = Node(id=rel[\"target\"], type=\"Unknown\")  # Temporary\n",
    "        graph_rels.append(map_to_base_relationship(Relationship(source=source_node, target=target_node, type=rel[\"type\"])))\n",
    "\n",
    "    # Create the structured GraphDocument with a source field\n",
    "    return GraphDocument(nodes=graph_nodes, relationships=graph_rels, source=Document(page_content=source_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_in_neo4j(graph_document):\n",
    "    \"\"\"\n",
    "    Stores extracted knowledge graph into Neo4j.\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        # Store nodes\n",
    "        for node in graph_document.nodes:\n",
    "            session.run(\"\"\"\n",
    "                MERGE (n:Entity {id: $id, type: $type})\n",
    "                SET n.name = $name\n",
    "            \"\"\", id=node.id, type=node.type, name=node.id)\n",
    "\n",
    "        # Store relationships\n",
    "        for rel in graph_document.relationships:\n",
    "            session.run(\"\"\"\n",
    "                MATCH (s:Entity {id: $source})\n",
    "                MATCH (t:Entity {id: $target})\n",
    "                MERGE (s)-[:RELATIONSHIP {type: $type}]->(t)\n",
    "            \"\"\", source=rel.source.id, target=rel.target.id, type=rel.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_railway_accident_report(text):\n",
    "    \n",
    "    print(\"🔹 Converting JSON to graph format...\")\n",
    "    graph_document = convert_json_to_graph(response_json, relevant_text)\n",
    "\n",
    "    if graph_document:\n",
    "        print(\"✅ Graph structure created! Storing in Neo4j...\")\n",
    "        store_in_neo4j(graph_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Converting JSON to graph format...\n",
      "✅ Graph structure created! Storing in Neo4j...\n",
      "Data stored in Neo4j successfully.\n"
     ]
    }
   ],
   "source": [
    "# Store extracted entities into Neo4j\n",
    "try:\n",
    "    db_result = process_railway_accident_report(response_json)\n",
    "    print(\"Data stored in Neo4j successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to store data in Neo4j:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Neo4j connection\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pdfplumber\n",
    "import json\n",
    "import os\n",
    "import regex as re\n",
    "import requests\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Models:\n",
      "==================================================\n",
      "ðŸ”¹ Model Name: deepseek-r1:latest\n",
      "   ðŸ”¸ Latest Version: deepseek-r1:latest\n",
      "   ðŸ”¸ Last Modified: 2025-01-22T11:28:16.966385195Z\n",
      "   ðŸ”¸ Size: 4.36 GB\n",
      "   ðŸ”¸ Parameter Size: 7.6B\n",
      "   ðŸ”¸ Quantization Level: Q4_K_M\n",
      "   ðŸ”¸ Model Family: qwen2\n",
      "==================================================\n",
      "ðŸ”¹ Model Name: mistral:latest\n",
      "   ðŸ”¸ Latest Version: mistral:latest\n",
      "   ðŸ”¸ Last Modified: 2024-11-18T13:04:07.029310353Z\n",
      "   ðŸ”¸ Size: 3.83 GB\n",
      "   ðŸ”¸ Parameter Size: 7.2B\n",
      "   ðŸ”¸ Quantization Level: Q4_0\n",
      "   ðŸ”¸ Model Family: llama\n",
      "==================================================\n",
      "ðŸ”¹ Model Name: llama3.1:latest\n",
      "   ðŸ”¸ Latest Version: llama3.1:latest\n",
      "   ðŸ”¸ Last Modified: 2024-11-18T13:04:06.322299249Z\n",
      "   ðŸ”¸ Size: 4.34 GB\n",
      "   ðŸ”¸ Parameter Size: 8.0B\n",
      "   ðŸ”¸ Quantization Level: Q4_0\n",
      "   ðŸ”¸ Model Family: llama\n",
      "==================================================\n",
      "ðŸ”¹ Model Name: falcon2:latest\n",
      "   ðŸ”¸ Latest Version: falcon2:latest\n",
      "   ðŸ”¸ Last Modified: 2024-11-18T13:04:05.01127866Z\n",
      "   ðŸ”¸ Size: 5.94 GB\n",
      "   ðŸ”¸ Parameter Size: 11B\n",
      "   ðŸ”¸ Quantization Level: Q4_0\n",
      "   ðŸ”¸ Model Family: falcon\n",
      "==================================================\n",
      "ðŸ”¹ Model Name: gemma2:latest\n",
      "   ðŸ”¸ Latest Version: gemma2:latest\n",
      "   ðŸ”¸ Last Modified: 2024-11-18T13:04:05.674289073Z\n",
      "   ðŸ”¸ Size: 5.07 GB\n",
      "   ðŸ”¸ Parameter Size: 9.2B\n",
      "   ðŸ”¸ Quantization Level: Q4_0\n",
      "   ðŸ”¸ Model Family: gemma2\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the API URL\n",
    "url = \"http://llama-max-ollama.ai.wu.ac.at/api/tags\"\n",
    "\n",
    "# Make the GET request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Convert response to JSON\n",
    "    \n",
    "    # Extract the list of models\n",
    "    models = data.get(\"models\", [])\n",
    "    \n",
    "    # Format and print each model's details\n",
    "    print(\"\\nAvailable Models:\\n\" + \"=\"*50)\n",
    "    for model in models:\n",
    "        print(f\"ðŸ”¹ Model Name: {model['name']}\")\n",
    "        print(f\"   ðŸ”¸ Latest Version: {model['model']}\")\n",
    "        print(f\"   ðŸ”¸ Last Modified: {model['modified_at']}\")\n",
    "        print(f\"   ðŸ”¸ Size: {model['size'] / (1024**3):.2f} GB\")  # Convert bytes to GB\n",
    "        print(f\"   ðŸ”¸ Parameter Size: {model['details'].get('parameter_size', 'Unknown')}\")\n",
    "        print(f\"   ðŸ”¸ Quantization Level: {model['details'].get('quantization_level', 'Unknown')}\")\n",
    "        print(f\"   ðŸ”¸ Model Family: {model['details'].get('family', 'Unknown')}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text Sample: Railway Accident\n",
      "Investigation Unit\n",
      "Ireland\n",
      "INVESTIGATION REPORT\n",
      "Collision between an IarnrÃ³d Ã‰ireann passenger\n",
      "train and rail-mounted maintenance equipment,\n",
      "Rosslare, Wexford, 11th January 2020\n",
      "RAIU Investigation Report No: 2020 â€“ R004\n",
      "Issued: 16th December 2020\n",
      "Collision between an IÃ‰ passenger train and RMME, Rosslare, Wexford, 11th January 2020\n",
      "Report Description\n",
      "Report publication\n",
      "This report is published by the Railway Accident Investigation Unit (RAIU). The copyright in\n",
      "the enclosed repor\n"
     ]
    }
   ],
   "source": [
    "# Extract the text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a given PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Test PDF extraction\n",
    "pdf_text = extract_text_from_pdf(\"./reports_ie/IE-6218-200111 Collision RRME Rosslare.pdf\")\n",
    "print(\"Extracted Text Sample:\", pdf_text[:500])  # Print first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Generated Summary:\n",
      "================================================================================\n",
      "<think> Alright, I need to figure out how to extract the date, time, and\n",
      "location from this given context. Let's start by reading through the text\n",
      "carefully.  First, I'll look for any dates mentioned. Scanning through, I see\n",
      "\"11th January 2020.\" That seems like a clear date: day, month, year. So that's\n",
      "one part done.  Next, checking for time information. The context doesn't mention\n",
      "any specific times when the collision occurred or when the report was issued. It\n",
      "only states the date of the collision and the publication date of the report. No\n",
      "hours or minutes are provided here, so I canâ€™t extract a time from this text.\n",
      "Now, for location. The collision happened in Rosslare, Wexford. Wexford is a\n",
      "city in Ireland, so that gives me both the town and the country. Since it\n",
      "doesn't specify a specific address within the town, just the general area as\n",
      "Rosslare, that should be sufficient for the location.  Putting this all\n",
      "together, I have the date as 11th January 2020, no time information, and the\n",
      "location as Rosslare in Wexford, Ireland. I'll structure this into a JSON object\n",
      "accordingly. </think>  ```json {   \"date\": \"11th January 2020\",   \"time\": null,\n",
      "\"location\": \"Rosslare, Wexford, Ireland\" } ```\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the API URL\n",
    "url = \"http://llama-max-ollama.ai.wu.ac.at/api/generate\"\n",
    "\n",
    "# Define the payload\n",
    "payload = {\n",
    "    \"model\": \"deepseek-r1:latest\",  # Ensure correct model name\n",
    "    \"prompt\": f\"Consider this context: {[pdf_text[:5000]]}. Please extract the entities date, time, and location. Output the information in JSON format.\",\n",
    "    \"stream\": False  # If 'raw' is unnecessary, remove it\n",
    "}\n",
    "\n",
    "# Set headers\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Send POST request\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "# Handle response\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        data = response.json()  # Parse response JSON\n",
    "        if \"response\" in data:\n",
    "            formatted_response = textwrap.fill(data[\"response\"], width=80)  # Wrap text for readability\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"Generated Summary:\")\n",
    "            print(\"=\"*80)\n",
    "            print(formatted_response)\n",
    "            print(\"=\"*80)\n",
    "        else:\n",
    "            print(\"No 'response' key found in the JSON.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Invalid JSON response: {response.text}\")\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pdfplumber\n",
    "import json\n",
    "import os\n",
    "import regex as re\n",
    "import requests\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Models:\n",
      "==================================================\n",
      "ðŸ”¹ Model Name: deepseek-r1:latest\n",
      "   ðŸ”¸ Latest Version: deepseek-r1:latest\n",
      "   ðŸ”¸ Last Modified: 2025-01-22T11:28:16.966385195Z\n",
      "   ðŸ”¸ Size: 4.36 GB\n",
      "   ðŸ”¸ Parameter Size: 7.6B\n",
      "   ðŸ”¸ Quantization Level: Q4_K_M\n",
      "   ðŸ”¸ Model Family: qwen2\n",
      "==================================================\n",
      "ðŸ”¹ Model Name: mistral:latest\n",
      "   ðŸ”¸ Latest Version: mistral:latest\n",
      "   ðŸ”¸ Last Modified: 2024-11-18T13:04:07.029310353Z\n",
      "   ðŸ”¸ Size: 3.83 GB\n",
      "   ðŸ”¸ Parameter Size: 7.2B\n",
      "   ðŸ”¸ Quantization Level: Q4_0\n",
      "   ðŸ”¸ Model Family: llama\n",
      "==================================================\n",
      "ðŸ”¹ Model Name: llama3.1:latest\n",
      "   ðŸ”¸ Latest Version: llama3.1:latest\n",
      "   ðŸ”¸ Last Modified: 2024-11-18T13:04:06.322299249Z\n",
      "   ðŸ”¸ Size: 4.34 GB\n",
      "   ðŸ”¸ Parameter Size: 8.0B\n",
      "   ðŸ”¸ Quantization Level: Q4_0\n",
      "   ðŸ”¸ Model Family: llama\n",
      "==================================================\n",
      "ðŸ”¹ Model Name: falcon2:latest\n",
      "   ðŸ”¸ Latest Version: falcon2:latest\n",
      "   ðŸ”¸ Last Modified: 2024-11-18T13:04:05.01127866Z\n",
      "   ðŸ”¸ Size: 5.94 GB\n",
      "   ðŸ”¸ Parameter Size: 11B\n",
      "   ðŸ”¸ Quantization Level: Q4_0\n",
      "   ðŸ”¸ Model Family: falcon\n",
      "==================================================\n",
      "ðŸ”¹ Model Name: gemma2:latest\n",
      "   ðŸ”¸ Latest Version: gemma2:latest\n",
      "   ðŸ”¸ Last Modified: 2024-11-18T13:04:05.674289073Z\n",
      "   ðŸ”¸ Size: 5.07 GB\n",
      "   ðŸ”¸ Parameter Size: 9.2B\n",
      "   ðŸ”¸ Quantization Level: Q4_0\n",
      "   ðŸ”¸ Model Family: gemma2\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the API URL\n",
    "url = \"http://llama-max-ollama.ai.wu.ac.at/api/tags\"\n",
    "\n",
    "# Make the GET request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Convert response to JSON\n",
    "    \n",
    "    # Extract the list of models\n",
    "    models = data.get(\"models\", [])\n",
    "    \n",
    "    # Format and print each model's details\n",
    "    print(\"\\nAvailable Models:\\n\" + \"=\"*50)\n",
    "    for model in models:\n",
    "        print(f\"ðŸ”¹ Model Name: {model['name']}\")\n",
    "        print(f\"   ðŸ”¸ Latest Version: {model['model']}\")\n",
    "        print(f\"   ðŸ”¸ Last Modified: {model['modified_at']}\")\n",
    "        print(f\"   ðŸ”¸ Size: {model['size'] / (1024**3):.2f} GB\")  # Convert bytes to GB\n",
    "        print(f\"   ðŸ”¸ Parameter Size: {model['details'].get('parameter_size', 'Unknown')}\")\n",
    "        print(f\"   ðŸ”¸ Quantization Level: {model['details'].get('quantization_level', 'Unknown')}\")\n",
    "        print(f\"   ðŸ”¸ Model Family: {model['details'].get('family', 'Unknown')}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text Sample: Railway Accident\n",
      "Investigation Unit\n",
      "Ireland\n",
      "INVESTIGATION REPORT\n",
      "Broken Rail near Emly,\n",
      "County Tipperary, 22nd February 2023\n",
      "RAIU Investigation Report No: 2024-R002\n",
      "Published: 22nd March 2024\n",
      "Broken Rail near Emly, County Tipperary, 22nd February 2023\n",
      "Report Description\n",
      "Report publication\n",
      "This report is published by the Railway Accident Investigation Unit (RAIU). The copyright in\n",
      "the enclosed report remains with the RAIU by virtue of in Regulation 9 (7) of European Union\n",
      "(EU) (Railway Safety) (R\n"
     ]
    }
   ],
   "source": [
    "# Extract the text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a given PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Test PDF extraction\n",
    "pdf_text = extract_text_from_pdf(\"raiu_example.pdf\")\n",
    "print(\"Extracted Text Sample:\", pdf_text[:500])  # Print first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 403: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "<hr><center>nginx/1.18.0 (Ubuntu)</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the API URL\n",
    "url = \"http://llama-max-ollama.ai.wu.ac.at/api/generate\"\n",
    "\n",
    "# Define the payload\n",
    "payload = {\n",
    "    \"model\": \"deepseek-r1:latest\",  # Ensure correct model name\n",
    "    \"prompt\": f\"Consider this context: {[pdf_text]}. Please extract the most important entities from this text. Output the information in JSON format.\",\n",
    "    \"stream\": False  # If 'raw' is unnecessary, remove it\n",
    "}\n",
    "\n",
    "# Set headers\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Send POST request\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "# Handle response\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        data = response.json()  # Parse response JSON\n",
    "        if \"response\" in data:\n",
    "            formatted_response = textwrap.fill(data[\"response\"], width=80)  # Wrap text for readability\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"Generated Summary:\")\n",
    "            print(\"=\"*80)\n",
    "            print(formatted_response)\n",
    "            print(\"=\"*80)\n",
    "        else:\n",
    "            print(\"No 'response' key found in the JSON.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Invalid JSON response: {response.text}\")\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
